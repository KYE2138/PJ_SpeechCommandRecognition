{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0-1. check and install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.10\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 2.6.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('tensorflow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 http://archive.ubuntu.com/ubuntu focal InRelease\n",
      "Hit:2 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
      "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n",
      "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  InRelease\n",
      "Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  Release\n",
      "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  Release\n",
      "Hit:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Reading package lists... Done3m\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "65 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "wget is already the newest version (1.20.3-1ubuntu2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 65 not upgraded.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "libsndfile1-dev is already the newest version (1.0.28-7ubuntu0.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 65 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!apt update\n",
    "!apt install wget\n",
    "!apt install libsndfile1-dev -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.8/dist-packages (22.0.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: librosa in /usr/local/lib/python3.8/dist-packages (0.9.1)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.0.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.19.5)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.8/dist-packages (from librosa) (5.1.0)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.2.2)\n",
      "Requirement already satisfied: numba>=0.45.1 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.55.1)\n",
      "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (21.2)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.8/dist-packages (from librosa) (0.10.3.post1)\n",
      "Requirement already satisfied: audioread>=2.1.5 in /usr/local/lib/python3.8/dist-packages (from librosa) (2.1.9)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from librosa) (1.8.0)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /usr/local/lib/python3.8/dist-packages (from numba>=0.45.1->librosa) (0.38.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.45.1->librosa) (58.4.0)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->librosa) (2.4.7)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/lib/python3/dist-packages (from pooch>=1.0->librosa) (2.22.0)\n",
      "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.8/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.19.1->librosa) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.20)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: python_speech_features in /usr/local/lib/python3.8/dist-packages (0.6)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: seaborn in /usr/local/lib/python3.8/dist-packages (0.11.2)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.8/dist-packages (from seaborn) (1.19.5)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.8/dist-packages (from seaborn) (3.4.3)\n",
      "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.8/dist-packages (from seaborn) (1.4.1)\n",
      "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.8/dist-packages (from seaborn) (1.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.15.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip \n",
    "!python -m pip install librosa\n",
    "!python -m pip install python_speech_features\n",
    "!python -m pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0-2. set parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set dataset path\n",
    "dataset_path = './data_speech_commands_v002'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1. get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# get speech_commands from google's server\n",
    "if not os.path.exists(dataset_path):\n",
    "    if not os.path.isfile('speech_commands_v0.02.tar.gz') :\n",
    "        !wget https://storage.googleapis.com/download.tensorflow.org/data/speech_commands_v0.02.tar.gz\n",
    "    !mkdir data_speech_commands_v002\n",
    "    !tar zxvf \"./speech_commands_v0.02.tar.gz\" --directory data_speech_commands_v002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2. dataset details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_dirslist: ['nine' 'eight' 'bed' 'bird' '.DS_Store' 'no' 'house' 'go' 'zero' 'marvin'\n",
      " 'dog' 'off' '_background_noise_' 'happy' 'stop' 'left' 'two' 'yes'\n",
      " 'testing_list.txt' 'on' 'learn' 'three' 'wow' 'tree' 'cat' 'right' 'down'\n",
      " 'six' 'LICENSE' 'five' 'backward' 'sheila' 'one' 'up' 'follow'\n",
      " 'validation_list.txt' 'README.md' 'visual' 'forward' 'seven' 'four'] , num:  41\n",
      "-\n",
      "dataset_commands_dirslist: ['nine' 'eight' 'bed' 'bird' 'no' 'house' 'go' 'zero' 'marvin' 'dog' 'off'\n",
      " 'happy' 'stop' 'left' 'two' 'yes' 'on' 'learn' 'three' 'wow' 'tree' 'cat'\n",
      " 'right' 'down' 'six' 'five' 'backward' 'sheila' 'one' 'up' 'follow'\n",
      " 'visual' 'forward' 'seven' 'four'] , num:  35\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# list the folders in the dataset\n",
    "dataset_dirslist = np.array(tf.io.gfile.listdir(str(dataset_path)))\n",
    "print ('dataset_dirslist:', dataset_dirslist,', num: ' , len(dataset_dirslist))\n",
    "print('-')\n",
    "\n",
    "# delete the files and folders which don't contain the trainable command folders from the list\n",
    "dataset_commands_dirslist = dataset_dirslist\n",
    "dataset_commands_dirslist = dataset_commands_dirslist[dataset_commands_dirslist != 'README.md']\n",
    "dataset_commands_dirslist = dataset_commands_dirslist[dataset_commands_dirslist != '.DS_Store']\n",
    "dataset_commands_dirslist = dataset_commands_dirslist[dataset_commands_dirslist != 'validation_list.txt']\n",
    "dataset_commands_dirslist = dataset_commands_dirslist[dataset_commands_dirslist != 'testing_list.txt']\n",
    "dataset_commands_dirslist = dataset_commands_dirslist[dataset_commands_dirslist != 'LICENSE']\n",
    "dataset_commands_dirslist = dataset_commands_dirslist[dataset_commands_dirslist != '_background_noise_']\n",
    "print ('dataset_commands_dirslist:', dataset_commands_dirslist,', num: ' , len(dataset_commands_dirslist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-3. dataset commands filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_commands_dir: ./data_speech_commands_v002/nine/*\n",
      "file num of nine : 3934\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/eight/*\n",
      "file num of eight : 3787\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/bed/*\n",
      "file num of bed : 2014\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/bird/*\n",
      "file num of bird : 2064\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/no/*\n",
      "file num of no : 3941\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/house/*\n",
      "file num of house : 2113\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/go/*\n",
      "file num of go : 3880\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/zero/*\n",
      "file num of zero : 4052\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/marvin/*\n",
      "file num of marvin : 2100\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/dog/*\n",
      "file num of dog : 2128\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/off/*\n",
      "file num of off : 3748\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/happy/*\n",
      "file num of happy : 2054\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/stop/*\n",
      "file num of stop : 3875\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/left/*\n",
      "file num of left : 3801\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/two/*\n",
      "file num of two : 3880\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/yes/*\n",
      "file num of yes : 4044\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/on/*\n",
      "file num of on : 3848\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/learn/*\n",
      "file num of learn : 1575\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/three/*\n",
      "file num of three : 3727\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/wow/*\n",
      "file num of wow : 2123\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/tree/*\n",
      "file num of tree : 1759\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/cat/*\n",
      "file num of cat : 2031\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/right/*\n",
      "file num of right : 3778\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/down/*\n",
      "file num of down : 3920\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/six/*\n",
      "file num of six : 3860\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/five/*\n",
      "file num of five : 4052\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/backward/*\n",
      "file num of backward : 1664\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/sheila/*\n",
      "file num of sheila : 2022\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/one/*\n",
      "file num of one : 3890\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/up/*\n",
      "file num of up : 3726\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/follow/*\n",
      "file num of follow : 1579\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/visual/*\n",
      "file num of visual : 1592\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/forward/*\n",
      "file num of forward : 1557\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/seven/*\n",
      "file num of seven : 3998\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/four/*\n",
      "file num of four : 3728\n",
      "-\n",
      "num of dataset_commands_filepaths: 35\n",
      "num of dataset_commands_filepaths: 105844\n",
      "sample of dataset_commands_filepaths: ./data_speech_commands_v002/nine/89947bd7_nohash_2.wav\n"
     ]
    }
   ],
   "source": [
    "# list the num of audio files in each command folder\n",
    "dataset_commands_filepaths = []\n",
    "for item in dataset_commands_dirslist:\n",
    "    dataset_commands_dir = os.path.join(dataset_path, item,'*')\n",
    "    print('dataset_commands_dir:', dataset_commands_dir)\n",
    "    fileslist = tf.io.gfile.glob(dataset_commands_dir)\n",
    "    print('file num of',item,':', len(fileslist))\n",
    "    dataset_commands_filepaths.extend(fileslist)\n",
    "    print('-')\n",
    "print('num of dataset_commands_filepaths:', len(dataset_commands_dirslist))\n",
    "print('num of dataset_commands_filepaths:', len(dataset_commands_filepaths))\n",
    "print('sample of dataset_commands_filepaths:', dataset_commands_filepaths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Audio Preporcess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1. function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1-1. split num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the start index to split the dataset  \n",
    "def get_split_num(train_ratio = 0.8, val_ratio = 0.1, test_ratio = 0.1, file_num = 0):\n",
    "    #get train , val, test num\n",
    "    train_num = int( file_num * train_ratio )\n",
    "    val_num = int( file_num * val_ratio )\n",
    "    test_num = file_num - train_num - val_num \n",
    "\n",
    "    #get train , val, test first_num\n",
    "    train_first_num = 0\n",
    "    val_first_num = train_num\n",
    "    test_first_num = train_num + val_num\n",
    "    \n",
    "    return train_first_num, val_first_num, test_first_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1-2. label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get label from the filepath of audio file\n",
    "def get_label(filepath):\n",
    "    split_1=os.path.split(filepath)\n",
    "    split_2=os.path.split(split_1[0])\n",
    "    return split_2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_label(dataset_commands_filepaths[0]):\n",
      "<class 'str'>\n",
      "nine\n"
     ]
    }
   ],
   "source": [
    "tmp = get_label(dataset_commands_filepaths[0])\n",
    "print ('get_label(dataset_commands_filepaths[0]):')\n",
    "print (type(tmp))\n",
    "print (tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1-3. waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "# load waveform from the filepath\n",
    "def get_waveform(filepath):\n",
    "    sample_rate = 16000\n",
    "    waveform, fs = librosa.load(filepath, sr=sample_rate)\n",
    "    return waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_waveform(dataset_commands_filepaths[0]):\n",
      "<class 'numpy.ndarray'>\n",
      "(16000,)\n",
      "[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  6.1035156e-04\n",
      " -1.5258789e-04 -9.1552734e-05]\n"
     ]
    }
   ],
   "source": [
    "tmp = get_waveform(dataset_commands_filepaths[0])\n",
    "print ('get_waveform(dataset_commands_filepaths[0]):')\n",
    "print (type(tmp))\n",
    "print (tmp.shape)\n",
    "print (tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1-4. label id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get label id from label and command_list\n",
    "def get_label_id(label,command_list):\n",
    "    label_id = np.argmax(label==command_list)\n",
    "    return label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_label_id(get_label(dataset_commands_filepaths[0]):\n",
      "<class 'numpy.int64'>\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "tmp = get_label_id(get_label(dataset_commands_filepaths[0]),dataset_commands_dirslist)\n",
    "print ('get_label_id(get_label(dataset_commands_filepaths[0]):')\n",
    "print (type(tmp))\n",
    "print (tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1-5. MFCC-python_speech_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import python_speech_features\n",
    "import matplotlib.pyplot as plt\n",
    "def get_features(waveform):\n",
    "    # Zero-padding for an audio waveform with less than 16,000 samples.\n",
    "    # input_len = 16000\n",
    "    # waveform = waveform[:input_len]\n",
    "    # np.shape(waveform) =  (16000,)\n",
    "    zero_padding = np.zeros( (16000-np.shape(waveform)[0],), dtype=np.float32)\n",
    "    # Cast the waveform tensors with np.float32\n",
    "    waveform = np.cast['float32'](waveform)\n",
    "    # Concatenate the waveform with `zero_padding`, which ensures all audio clips are of the same length.\n",
    "    equal_length = np.concatenate([waveform, zero_padding], 0)\n",
    "    \n",
    "    sample_rate = 16000\n",
    "    num_mfcc = 16\n",
    "    len_mfcc = 40\n",
    "    mfccs = python_speech_features.base.mfcc(equal_length, \n",
    "                                            samplerate=sample_rate,\n",
    "                                            winlen=0.256,\n",
    "                                            winstep=0.050,\n",
    "                                            numcep=num_mfcc,\n",
    "                                            nfilt=26,\n",
    "                                            nfft=4096,\n",
    "                                            preemph=0.0,\n",
    "                                            ceplifter=0,\n",
    "                                            appendEnergy=False,\n",
    "                                            winfunc=np.hanning)\n",
    "    return mfccs.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_features(get_waveform(dataset_commands_files[0])):\n",
      "type: <class 'numpy.ndarray'>\n",
      "shape: (16, 16)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp = get_features(get_waveform(dataset_commands_filepaths[0]))\n",
    "print ('get_features(get_waveform(dataset_commands_files[0])):')\n",
    "print ('type:',type(tmp))\n",
    "print ('shape:',tmp.shape)\n",
    "#print (tmp)\n",
    "fig = plt.figure()\n",
    "plt.imshow(tmp, cmap='inferno', origin='lower')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2. Preporcess set commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_val = []\n",
    "y_val = []\n",
    "x_test = []\n",
    "y_test = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2-1. get set command filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_commands_dir: ./data_speech_commands_v002/on/*\n",
      "file num : 3848\n",
      "-\n",
      "set_commands_dir: ./data_speech_commands_v002/off/*\n",
      "file num : 3748\n",
      "-\n",
      "set_commands_dir: ./data_speech_commands_v002/up/*\n",
      "file num : 3726\n",
      "-\n",
      "set_commands_dir: ./data_speech_commands_v002/down/*\n",
      "file num : 3920\n",
      "-\n",
      "set_commands_dir: ./data_speech_commands_v002/stop/*\n",
      "file num : 3875\n",
      "-\n",
      "num of train_set_commands_filepaths: 15292\n",
      "num of val_set_commands_filepaths: 1909\n",
      "num of test_set_commands_filepaths: 1916\n",
      "total of set_commands_filepaths: 19117\n",
      "sample of train_set_commands_filepaths: ./data_speech_commands_v002/on/e57d35bc_nohash_0.wav\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(66)\n",
    "\n",
    "# set want commands\n",
    "commands = np.array(['on','off','up','down','stop'])\n",
    "\n",
    "train_set_commands_filepaths = []\n",
    "val_set_commands_filepaths = []\n",
    "test_set_commands_filepaths = []\n",
    "\n",
    "# get set commands\n",
    "set_commands_dirslist = commands\n",
    "# get the filepaths and split to train, val, test every command\n",
    "for item in set_commands_dirslist:\n",
    "    # join the dataset_path and command\n",
    "    set_commands_dir = os.path.join(dataset_path, item,'*')\n",
    "    print('set_commands_dir:', set_commands_dir)\n",
    "    \n",
    "    # list the set command filepaths in each dir\n",
    "    fileslist = tf.io.gfile.glob(set_commands_dir)\n",
    "    random.shuffle(fileslist)\n",
    "    print('file num :', len(fileslist))\n",
    "    print('-')\n",
    "    \n",
    "    # split the filslist to train, val, test\n",
    "    train, val, test = get_split_num(0.8, 0.1, 0.1, len(fileslist))\n",
    "    train_set_commands_filepaths.extend(fileslist[:val])\n",
    "    val_set_commands_filepaths.extend(fileslist[val:test])\n",
    "    test_set_commands_filepaths.extend(fileslist[test:])  \n",
    "# get the num of all tarinable audio files\n",
    "total_set_commands_num = len(train_set_commands_filepaths)+len(val_set_commands_filepaths)+len(test_set_commands_filepaths)\n",
    "    \n",
    "print('num of train_set_commands_filepaths:', len(train_set_commands_filepaths))\n",
    "print('num of val_set_commands_filepaths:', len(val_set_commands_filepaths))\n",
    "print('num of test_set_commands_filepaths:', len(test_set_commands_filepaths))\n",
    "\n",
    "print('total of set_commands_filepaths:',total_set_commands_num)\n",
    "print('sample of train_set_commands_filepaths:', train_set_commands_filepaths[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2-2. get features and label id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_commands_features = []\n",
    "val_set_commands_features = []\n",
    "test_set_commands_features = []\n",
    "\n",
    "train_set_commands_label_id = []\n",
    "val_set_commands_label_id = []\n",
    "test_set_commands_label_id = []\n",
    "\n",
    "# get features and label id and append to train_set_commands_features and train_set_commands_label_id\n",
    "for i, item in enumerate(train_set_commands_filepaths):\n",
    "    waveform = get_waveform(item)\n",
    "    features = get_features(waveform)\n",
    "    train_set_commands_features.append(features)\n",
    "\n",
    "    label = get_label(item)\n",
    "    label_id = get_label_id(label,commands)\n",
    "    train_set_commands_label_id.append(label_id)\n",
    "\n",
    "    \n",
    "# get features and label id and append to val_set_commands_features and val_set_commands_label_id\n",
    "for i, item in enumerate(val_set_commands_filepaths):\n",
    "    waveform = get_waveform(item)\n",
    "    features = get_features(waveform)\n",
    "    val_set_commands_features.append(features)\n",
    "\n",
    "    label = get_label(item)\n",
    "    label_id = get_label_id(label,commands)\n",
    "    val_set_commands_label_id.append(label_id)\n",
    "\n",
    "# get features and label id and append to test_set_commands_features and test_set_commands_label_id    \n",
    "for i, item in enumerate(test_set_commands_filepaths):\n",
    "    waveform = get_waveform(item)\n",
    "    features = get_features(waveform)\n",
    "    test_set_commands_features.append(features)\n",
    "\n",
    "    label = get_label(item)\n",
    "    label_id = get_label_id(label,commands)\n",
    "    test_set_commands_label_id.append(label_id)        \n",
    "        \n",
    "\n",
    "print ('num of train_set_commands_features:', len(train_set_commands_features))\n",
    "print ('num of train_set_commands_label_id:', len(train_set_commands_label_id))\n",
    "print('-')\n",
    "print ('num of val_set_commands_features:', len(val_set_commands_features))\n",
    "print ('num of val_set_commands_label_id:', len(val_set_commands_label_id))\n",
    "print('-')\n",
    "print ('num of test_set_commands_features:', len(test_set_commands_features))\n",
    "print ('num of test_set_commands_label_id:', len(test_set_commands_label_id)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2-3. add features and label id to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add features and label id to train list\n",
    "x_train.extend(train_set_commands_features)\n",
    "y_train.extend(train_set_commands_label_id)\n",
    "\n",
    "# add features and label id to val list\n",
    "x_val.extend(val_set_commands_features)\n",
    "y_val.extend(val_set_commands_label_id)\n",
    "\n",
    "# add features and label id to test list\n",
    "x_test.extend(test_set_commands_features)\n",
    "y_test.extend(test_set_commands_label_id)\n",
    "\n",
    "print('num of x_train:',len(y_train))\n",
    "print('num of y_train:',len(y_train))\n",
    "print('-')\n",
    "print('num of x_val:',len(x_val))\n",
    "print('num of y_val:',len(y_val))\n",
    "print('-')\n",
    "print('num of x_test:',len(x_test))\n",
    "print('num of y_test:',len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-3. Preporcess unknown commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3-1. get unknown command filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unknown_commands_filepaths = []\n",
    "val_unknown_commands_filepaths = []\n",
    "test_unknown_commands_filepaths = []\n",
    "\n",
    "# add unknown to commands list\n",
    "if not np.any(commands=='unknown'):\n",
    "    commands = np.append(commands,'unknown')\n",
    "print ('commands:',commands)\n",
    "print('-')\n",
    "\n",
    "# get the unknown commands which are not set commands and add them to the list\n",
    "unknown_commands_dirslist = np.setdiff1d( dataset_commands_dirslist , commands)\n",
    "print ('unknown_commands_dirslist:',unknown_commands_dirslist)\n",
    "print('-')\n",
    "\n",
    "# set the ratio of unknown command filepaths to set command filepaths\n",
    "unknown_ratio = 0.1\n",
    "print('unknown_ratio:',unknown_ratio)\n",
    "print ('total_set_commands_num:', total_set_commands_num)\n",
    "# get the num of unknown command filepaths\n",
    "unknown_command_num = int(total_set_commands_num * unknown_ratio)\n",
    "print ('unknown_command_num:', unknown_command_num)\n",
    "# get the the num of each unknown command filepaths\n",
    "each_unknown_command_num = unknown_command_num//len(unknown_commands_dirslist)\n",
    "print ('each_unknown_command_num:', each_unknown_command_num)\n",
    "print('-')\n",
    "\n",
    "# get the filepaths and split to train, val, test every command\n",
    "for item in unknown_commands_dirslist:\n",
    "    # join the dataset_path and command\n",
    "    unknown_commands_dir = os.path.join(dataset_path, item,'*')\n",
    "    print('unknown_commands_dir:', unknown_commands_dir)\n",
    "    \n",
    "    # list the unknown command filepaths in each dir\n",
    "    fileslist = tf.io.gfile.glob(unknown_commands_dir)\n",
    "    random.shuffle(fileslist)\n",
    "    print('file num :', len(fileslist))\n",
    "    \n",
    "    # split the filslist to train, val, test\n",
    "    train, val, test = get_split_num(0.8, 0.1, 0.1, each_unknown_command_num)\n",
    "    train_unknown_commands_filepaths.extend(fileslist[:val])\n",
    "    val_unknown_commands_filepaths.extend(fileslist[val:test])\n",
    "    test_unknown_commands_filepaths.extend(fileslist[test:each_unknown_command_num])\n",
    "    print('-')\n",
    "    \n",
    "print('num of train_unknown_commands_filepaths:', len(train_unknown_commands_filepaths))\n",
    "print('num of val_unknown_commands_filepaths:', len(val_unknown_commands_filepaths))\n",
    "print('num of test_unknown_commands_filepaths:', len(test_unknown_commands_filepaths))\n",
    "print('sample of train_unknown_commands_filepaths:', train_unknown_commands_filepaths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3-2. get features and label id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unknown_commands_features = []\n",
    "val_unknown_commands_features = []\n",
    "test_unknown_commands_features = []\n",
    "\n",
    "train_unknown_commands_label_id = []\n",
    "val_unknown_commands_label_id = []\n",
    "test_unknown_commands_label_id = []\n",
    "\n",
    "# get the unknown label and label_id\n",
    "label = 'unknown'\n",
    "label_id = get_label_id(label,commands)\n",
    "\n",
    "# get features and label id and append to train_unknown_commands_features and train_unknown_commands_label_id\n",
    "for i, item in enumerate(train_unknown_commands_filepaths):\n",
    "    waveform = get_waveform(item)\n",
    "    features = get_features(waveform)\n",
    "    train_unknown_commands_features.append(features)\n",
    "    train_unknown_commands_label_id.append(label_id)\n",
    "\n",
    "# get features and label id and append to val_unknown_commands_features and val_unknown_commands_label_id\n",
    "for i, item in enumerate(val_unknown_commands_filepaths):\n",
    "    waveform = get_waveform(item)\n",
    "    features = get_features(waveform)\n",
    "    val_unknown_commands_features.append(features)\n",
    "    val_unknown_commands_label_id.append(label_id)\n",
    "\n",
    "# get features and label id and append to test_unknown_commands_features and test_unknown_commands_label_id\n",
    "for i, item in enumerate(test_unknown_commands_filepaths):\n",
    "    waveform = get_waveform(item)\n",
    "    features = get_features(waveform)\n",
    "    test_unknown_commands_features.append(features)\n",
    "    test_unknown_commands_label_id.append(label_id)        \n",
    "        \n",
    "\n",
    "print ('num of train_unknown_commands_features:', len(train_unknown_commands_features))\n",
    "print ('num of train_unknown_commands_label_id:', len(train_unknown_commands_label_id))\n",
    "print('-')\n",
    "print ('num of val_unknown_commands_features:', len(val_unknown_commands_features))\n",
    "print ('num of val_unknown_commands_label_id:', len(val_unknown_commands_label_id))\n",
    "print('-')\n",
    "print ('num of test_unknown_commands_features:', len(test_unknown_commands_features))\n",
    "print ('num of test_unknown_commands_label_id:', len(test_unknown_commands_label_id)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3-3. add features and label id to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add features and label id to train list\n",
    "x_train.extend(train_unknown_commands_features)\n",
    "y_train.extend(train_unknown_commands_label_id)\n",
    "# add features and label id to val list\n",
    "x_val.extend(val_unknown_commands_features)\n",
    "y_val.extend(val_unknown_commands_label_id)\n",
    "# add features and label id to test list\n",
    "x_test.extend(test_unknown_commands_features)\n",
    "y_test.extend(test_unknown_commands_label_id)\n",
    "\n",
    "print('num of x_train:',len(x_train))\n",
    "print('num of y_train:',len(y_train))\n",
    "print('-')\n",
    "print('num of x_val:',len(x_val))\n",
    "print('num of y_val:',len(y_val))\n",
    "print('-')\n",
    "print('num of x_test:',len(x_test))\n",
    "print('num of y_test:',len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-4. Preporcess slience command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4-1. get background command filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_slience_commands_filepaths = []\n",
    "val_slience_commands_filepaths = []\n",
    "test_slience_commands_filepaths = []\n",
    "\n",
    "# add slience command to commands list\n",
    "if not np.any(commands=='slience'):\n",
    "    commands = np.append(commands,'slience')\n",
    "print ('commands:',commands)\n",
    "print('-')\n",
    "\n",
    "# get background_noise to contruct slience samples\n",
    "slience_commands_dirslist = ['_background_noise_']\n",
    "print ('slience_commands_dirslist:',slience_commands_dirslist)\n",
    "print('-')\n",
    "\n",
    "# set the ratio of slience samples to set command filepaths\n",
    "slience_ratio = 0.1\n",
    "print ('total_set_commands_num:', total_set_commands_num)\n",
    "print('slience_ratio:',slience_ratio)\n",
    "# get the num of slience samples\n",
    "slience_command_num = int(total_set_commands_num * slience_ratio)\n",
    "print ('slience_command_num:', slience_command_num)\n",
    "print('-')\n",
    "\n",
    "# get the background_noise filepaths and append to train, val, test every filepaths\n",
    "for item in slience_commands_dirslist:\n",
    "    # join the dataset_path and background_noise files\n",
    "    slience_commands_dir = os.path.join(dataset_path, item,'*.wav')\n",
    "    print('slience_commands_dir:', slience_commands_dir)\n",
    "    \n",
    "    # get list of background_noise files\n",
    "    fileslist = tf.io.gfile.glob(slience_commands_dir)\n",
    "    print('file num :', len(fileslist))\n",
    "    \n",
    "    # get num of each background_noise files (the num to append for each files)\n",
    "    each_slience_files = slience_command_num//len(fileslist)\n",
    "    print ('each_slience_files:', each_slience_files)\n",
    "  \n",
    "    # get num of tarin , val ,test for each files\n",
    "    train_num = int(each_slience_files*0.8)\n",
    "    val_num = int(each_slience_files*0.1)\n",
    "    test_num = int(each_slience_files*0.1)\n",
    "    print('-')\n",
    "    \n",
    "    # every background_noise file\n",
    "    for itme in fileslist:\n",
    "        # append the filepath to train,val,test list for each files\n",
    "        for i in range(train_num):\n",
    "            train_slience_commands_filepaths.append(itme)\n",
    "        for i in range(val_num):\n",
    "            val_slience_commands_filepaths.append(itme)\n",
    "        for i in range(test_num):\n",
    "            test_slience_commands_filepaths.append(itme)\n",
    "\n",
    "print('num of train_slience_commands_filepaths:', len(train_slience_commands_filepaths))\n",
    "print('num of val_slience_commands_filepaths:', len(val_slience_commands_filepaths))\n",
    "print('num of test_slience_commands_filepaths:', len(test_slience_commands_filepaths))\n",
    "print('sample of train_slience_commands_filepaths:', train_slience_commands_filepaths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4-2. contruct slience features and label id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ontruct slience features from background_noise\n",
    "def get_random_background_noise_waveform(filepath):\n",
    "    # get waveform and len from filepath\n",
    "    waveform = get_waveform(filepath)  \n",
    "    waveform_len = waveform.shape[0]\n",
    "    # get start time by random(waveform_len)\n",
    "    split_start_time = random.randrange(0, waveform_len)\n",
    "    # get the 1s background_noise sample to represent slience feature\n",
    "    waveform_split = waveform[split_start_time:split_start_time+16000]\n",
    "    return waveform_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contruct slience features by zero vector\n",
    "def get_zero_waveform():\n",
    "    # get the 1s zero vector sample to represent slience feature\n",
    "    zero_waveform = np.zeros((16000,), dtype=np.float32)\n",
    "    return zero_waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_slience_commands_features = []\n",
    "val_slience_commands_features = []\n",
    "test_slience_commands_features = []\n",
    "\n",
    "train_slience_commands_label_id = []\n",
    "val_slience_commands_label_id = []\n",
    "test_slience_commands_label_id = []\n",
    "\n",
    "# get the slience label and label_id\n",
    "label = 'slience'\n",
    "label_id = get_label_id(label,commands)\n",
    "\n",
    "# get features and label id by get_random_background_noise_waveform and append them to train list\n",
    "for i, item in enumerate(train_slience_commands_filepaths):\n",
    "    background_noise_waveform = get_random_background_noise_waveform(item)\n",
    "    features = get_features(background_noise_waveform)\n",
    "    train_slience_commands_features.append(features)\n",
    "    train_slience_commands_label_id.append(label_id)\n",
    "# get features and label id by get_zero_waveform and append one sample to train list\n",
    "zero_waveform = get_zero_waveform()\n",
    "features = get_features(zero_waveform)\n",
    "train_slience_commands_features.append(features)\n",
    "train_slience_commands_label_id.append(label_id)\n",
    "\n",
    "# get features and label id by get_random_background_noise_waveform and append them to val list\n",
    "for i, item in enumerate(val_slience_commands_filepaths):\n",
    "    background_noise_waveform = get_random_background_noise_waveform(item)\n",
    "    features = get_features(background_noise_waveform)\n",
    "    val_slience_commands_features.append(features)\n",
    "    val_slience_commands_label_id.append(label_id)    \n",
    "# get features and label id by get_zero_waveform and append one sample to val list\n",
    "zero_waveform = get_zero_waveform()\n",
    "features = get_features(zero_waveform)\n",
    "val_slience_commands_features.append(features)\n",
    "val_slience_commands_label_id.append(label_id)\n",
    "\n",
    "# get features and label id by get_random_background_noise_waveform and append them to test list\n",
    "for i, item in enumerate(test_slience_commands_filepaths):\n",
    "    background_noise_waveform = get_random_background_noise_waveform(item)\n",
    "    features = get_features(background_noise_waveform)\n",
    "    test_slience_commands_features.append(features)\n",
    "    test_slience_commands_label_id.append(label_id)    \n",
    "# get features and label id by get_zero_waveform and append one sample to test list\n",
    "zero_waveform = get_zero_waveform()\n",
    "features = get_features(zero_waveform)\n",
    "test_slience_commands_features.append(features)\n",
    "test_slience_commands_label_id.append(label_id)\n",
    "\n",
    "print ('num of train_slience_commands_features:', len(train_slience_commands_features))\n",
    "print ('num of train_slience_commands_label_id:', len(train_slience_commands_label_id))\n",
    "print('-')\n",
    "print ('num of val_slience_commands_features:', len(val_slience_commands_features))\n",
    "print ('num of val_slience_commands_label_id:', len(val_slience_commands_label_id))\n",
    "print('-')\n",
    "print ('num of test_slience_commands_features:', len(test_slience_commands_features))\n",
    "print ('num of test_slience_commands_label_id:', len(test_slience_commands_label_id)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4-3. add features and label id to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add features and label id to train list\n",
    "x_train.extend(train_slience_commands_features)\n",
    "y_train.extend(train_slience_commands_label_id)\n",
    "# add features and label id to val list\n",
    "x_val.extend(val_slience_commands_features)\n",
    "y_val.extend(val_slience_commands_label_id)\n",
    "# add features and label id to test list\n",
    "x_test.extend(test_slience_commands_features)\n",
    "y_test.extend(test_slience_commands_label_id)\n",
    "\n",
    "print('num of x_train:',len(x_train))\n",
    "print('num of y_train:',len(y_train))\n",
    "print('-')\n",
    "print('num of x_val:',len(x_val))\n",
    "print('num of y_val:',len(y_val))\n",
    "print('-')\n",
    "print('num of x_test:',len(x_test))\n",
    "print('num of y_test:',len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-5.  save and load processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sets_file = 'all_targets_mfcc_sets.npz'\n",
    "# Save features and truth vector (y) sets to disk\n",
    "np.savez(feature_sets_file, \n",
    "         x_train=x_train, \n",
    "         y_train=y_train, \n",
    "         x_val=x_val, \n",
    "         y_val=y_val, \n",
    "         x_test=x_test, \n",
    "         y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sets_path = './'\n",
    "feature_sets_filename = 'all_targets_mfcc_sets.npz'\n",
    "# Load feature sets\n",
    "feature_sets = np.load(os.path.join(feature_sets_path, feature_sets_filename))\n",
    "print(feature_sets.files)\n",
    "# Assign feature sets\n",
    "x_train = feature_sets['x_train']\n",
    "y_train = feature_sets['y_train']\n",
    "x_val = feature_sets['x_val']\n",
    "y_val = feature_sets['y_val']\n",
    "x_test = feature_sets['x_test']\n",
    "y_test = feature_sets['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1. prepare input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip and shuffle \n",
    "train_list = list(zip(x_train, y_train))\n",
    "random.shuffle(train_list)\n",
    "x_train, y_train = zip(*train_list)\n",
    "\n",
    "val_list = list(zip(x_val, y_val))\n",
    "random.shuffle(val_list)\n",
    "x_val, y_val = zip(*val_list)\n",
    "\n",
    "test_list = list(zip(x_test, y_test))\n",
    "random.shuffle(test_list)\n",
    "x_test, y_test = zip(*test_list)\n",
    "\n",
    "# trans to np.array to expand dims\n",
    "x_tn = np.array(x_train)\n",
    "y_tn = np.array(y_train)\n",
    "x_v = np.array(x_val)\n",
    "y_v = np.array(y_val)\n",
    "x_ts = np.array(x_test)\n",
    "y_ts = np.array(y_test)\n",
    "\n",
    "# expand dims to satifiy input shape\n",
    "x_tn = np.expand_dims(x_tn, axis=-1)\n",
    "x_v = np.expand_dims(x_v, axis=-1)\n",
    "x_ts = np.expand_dims(x_ts, axis=-1)\n",
    "\n",
    "print (x_tn.shape)\n",
    "print (y_tn.shape)\n",
    "print (x_v.shape)\n",
    "print (y_v.shape)\n",
    "print (x_ts.shape)\n",
    "print (y_ts.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2. set parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get and check input shape by sampling \n",
    "tmp = get_features(get_waveform(dataset_commands_filepaths[0]))\n",
    "tmp = np.expand_dims(tmp, axis=-1)\n",
    "input_shape = tmp.shape\n",
    "print('Input shape:', input_shape)\n",
    "# get and check output shape by num of commands\n",
    "num_labels = len(commands)\n",
    "print('Output shape:', num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-3. build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "# build a model\n",
    "model = models.Sequential([\n",
    "    \n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.Conv2D(32, (3,3)),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Conv2D(32, (3,3)),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Conv2D(64, (3,3)),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.1),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(num_labels),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-4. train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "EPOCHS = 20\n",
    "history = model.fit(\n",
    "    x_tn,y_tn,\n",
    "    validation_data=(x_v,y_v),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=64,\n",
    "    callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=3),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-5. result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# determine overfitting by checking the metrics\n",
    "metrics = history.history\n",
    "plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-6. save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model file name\n",
    "model_filename = 'SpeechCommandRecognition_model.h5'\n",
    "# Save the model as a file\n",
    "models.save_model(model, model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-7. evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference on test set\n",
    "y_pred = np.argmax(model.predict(x_ts), axis=1)\n",
    "#print(y_pred)\n",
    "y_true = y_ts\n",
    "#print (y_true)\n",
    "test_acc = sum(y_pred == y_true) / len(y_true)\n",
    "print(f'Test set accuracy: {test_acc:.0%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-8. display a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# check the result the confusion_matrix \n",
    "confusion_mtx = tf.math.confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion_mtx,\n",
    "            xticklabels=commands,\n",
    "            yticklabels=commands,\n",
    "            annot=True, fmt='g')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-9. run inference on an audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run inference on an audio file\n",
    "audio_file = os.path.join(dataset_path, 'on','0ba018fc_nohash_1.wav')\n",
    "sample_feature = get_features(get_waveform(audio_file))\n",
    "sample_feature = np.expand_dims(sample_feature, axis=-1)\n",
    "sample_feature = np.expand_dims(sample_feature, axis=0)\n",
    "\n",
    "sample_label = get_label(audio_file)\n",
    "sample_label_id = get_label_id(sample_label, commands)\n",
    "\n",
    "prediction = model(sample_feature)\n",
    "plt.bar(commands, tf.nn.softmax(prediction[0]))\n",
    "plt.title(f'Predictions for \"{commands[sample_label_id]}\"')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-1. set parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import lite\n",
    "from tensorflow.keras import models\n",
    "# set the file name\n",
    "keras_model_filename = 'SpeechCommandRecognition_model.h5'\n",
    "tflite_filename = 'SpeechCommandRecognition_model.tflite'\n",
    "tflite_quantization_filename = 'SpeechCommandRecognition_quantization_model.tflite'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-2. convert (float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model to the TensorFlow Lite format without quantization\n",
    "model = models.load_model(keras_model_filename)\n",
    "converter = lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "open(tflite_filename, 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp SpeechCommandRecognition_model.tflite ../Inference/SpeechCommandRecognition_model.tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
