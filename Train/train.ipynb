{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0-1. check and install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.9\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 2.4.3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('tensorflow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!apt update\n",
    "#!apt install wget\n",
    "#!apt install libsndfile1-dev -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m pip install --upgrade pip \n",
    "#!python -m pip install librosa\n",
    "#!python -m pip install python_speech_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0-2. set parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = './data_speech_commands_v002'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "commands = np.array(['yes','no','on','off'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1. get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(dataset_path):\n",
    "    if not os.path.isfile('speech_commands_v0.02.tar.gz') :\n",
    "        !wget https://storage.googleapis.com/download.tensorflow.org/data/speech_commands_v0.02.tar.gz\n",
    "    !mkdir data_speech_commands_v002\n",
    "    !tar zxvf \"./speech_commands_v0.02.tar.gz\" --directory data_speech_commands_v002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2. dataset details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_dirslist: ['dog' 'backward' 'happy' 'forward' 'cat' 'testing_list.txt'\n",
      " '_background_noise_' 'up' 'LICENSE' 'README.md' 'off' 'follow' 'sheila'\n",
      " 'nine' 'marvin' 'bed' 'right' 'five' 'six' 'seven' 'yes' 'down' 'wow'\n",
      " 'four' '.DS_Store' 'on' 'eight' 'left' 'learn' 'two'\n",
      " 'validation_list.txt' 'tree' 'zero' 'house' 'visual' 'go' 'stop' 'no'\n",
      " 'three' 'bird' 'one'] , num:  41\n",
      "-\n",
      "dataset_commands_dirslist: ['dog' 'backward' 'happy' 'forward' 'cat' 'up' 'off' 'follow' 'sheila'\n",
      " 'nine' 'marvin' 'bed' 'right' 'five' 'six' 'seven' 'yes' 'down' 'wow'\n",
      " 'four' 'on' 'eight' 'left' 'learn' 'two' 'tree' 'zero' 'house' 'visual'\n",
      " 'go' 'stop' 'no' 'three' 'bird' 'one'] , num:  35\n"
     ]
    }
   ],
   "source": [
    "dataset_dirslist = np.array(tf.io.gfile.listdir(str(dataset_path)))\n",
    "print ('dataset_dirslist:', dataset_dirslist,', num: ' , len(dataset_dirslist))\n",
    "print('-')\n",
    "\n",
    "dataset_commands_dirslist = dataset_dirslist\n",
    "dataset_commands_dirslist = dataset_commands_dirslist[dataset_commands_dirslist != 'README.md']\n",
    "dataset_commands_dirslist = dataset_commands_dirslist[dataset_commands_dirslist != '.DS_Store']\n",
    "dataset_commands_dirslist = dataset_commands_dirslist[dataset_commands_dirslist != 'validation_list.txt']\n",
    "dataset_commands_dirslist = dataset_commands_dirslist[dataset_commands_dirslist != 'testing_list.txt']\n",
    "dataset_commands_dirslist = dataset_commands_dirslist[dataset_commands_dirslist != 'LICENSE']\n",
    "dataset_commands_dirslist = dataset_commands_dirslist[dataset_commands_dirslist != '_background_noise_']\n",
    "print ('dataset_commands_dirslist:', dataset_commands_dirslist,', num: ' , len(dataset_commands_dirslist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-3. dataset commands filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_commands_dir: ./data_speech_commands_v002/dog/*\n",
      "file num of dog : 2128\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/backward/*\n",
      "file num of backward : 1664\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/happy/*\n",
      "file num of happy : 2054\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/forward/*\n",
      "file num of forward : 1557\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/cat/*\n",
      "file num of cat : 2031\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/up/*\n",
      "file num of up : 3723\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/off/*\n",
      "file num of off : 3745\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/follow/*\n",
      "file num of follow : 1579\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/sheila/*\n",
      "file num of sheila : 2022\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/nine/*\n",
      "file num of nine : 3934\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/marvin/*\n",
      "file num of marvin : 2100\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/bed/*\n",
      "file num of bed : 2014\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/right/*\n",
      "file num of right : 3778\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/five/*\n",
      "file num of five : 4052\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/six/*\n",
      "file num of six : 3860\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/seven/*\n",
      "file num of seven : 3998\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/yes/*\n",
      "file num of yes : 4044\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/down/*\n",
      "file num of down : 3917\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/wow/*\n",
      "file num of wow : 2123\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/four/*\n",
      "file num of four : 3728\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/on/*\n",
      "file num of on : 3845\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/eight/*\n",
      "file num of eight : 3787\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/left/*\n",
      "file num of left : 3801\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/learn/*\n",
      "file num of learn : 1575\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/two/*\n",
      "file num of two : 3880\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/tree/*\n",
      "file num of tree : 1759\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/zero/*\n",
      "file num of zero : 4052\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/house/*\n",
      "file num of house : 2113\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/visual/*\n",
      "file num of visual : 1592\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/go/*\n",
      "file num of go : 3880\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/stop/*\n",
      "file num of stop : 3872\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/no/*\n",
      "file num of no : 3941\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/three/*\n",
      "file num of three : 3727\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/bird/*\n",
      "file num of bird : 2064\n",
      "-\n",
      "dataset_commands_dir: ./data_speech_commands_v002/one/*\n",
      "file num of one : 3890\n",
      "-\n",
      "num of dataset_commands_filepaths: 35\n",
      "num of dataset_commands_filepaths: 105829\n",
      "sample of dataset_commands_filepaths: ./data_speech_commands_v002/dog/6794a793_nohash_0.wav\n"
     ]
    }
   ],
   "source": [
    "dataset_commands_filepaths = []\n",
    "for item in dataset_commands_dirslist:\n",
    "    dataset_commands_dir = os.path.join(dataset_path, item,'*')\n",
    "    print('dataset_commands_dir:', dataset_commands_dir)\n",
    "    fileslist = tf.io.gfile.glob(dataset_commands_dir)\n",
    "    print('file num of',item,':', len(fileslist))\n",
    "    dataset_commands_filepaths.extend(fileslist)\n",
    "    print('-')\n",
    "print('num of dataset_commands_filepaths:', len(dataset_commands_dirslist))\n",
    "print('num of dataset_commands_filepaths:', len(dataset_commands_filepaths))\n",
    "print('sample of dataset_commands_filepaths:', dataset_commands_filepaths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Audio Preporcess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1. function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1-1. split num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_num(train_ratio = 0.8, val_ratio = 0.1, test_ratio = 0.1, file_num = 0):\n",
    "    #get train , val, test num\n",
    "    train_num = int( file_num * train_ratio )\n",
    "    val_num = int( file_num * val_ratio )\n",
    "    test_num = file_num - train_num - val_num \n",
    "\n",
    "    #get train , val, test first_num\n",
    "    train_first_num = 0\n",
    "    val_first_num = train_num\n",
    "    test_first_num = train_num + val_num\n",
    "    \n",
    "    return train_first_num, val_first_num, test_first_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1-2. label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_label(dataset_commands_filepaths[0]):\n",
      "<class 'str'>\n",
      "dog\n"
     ]
    }
   ],
   "source": [
    "def get_label(filepath):\n",
    "    split_1=os.path.split(filepath)\n",
    "    split_2=os.path.split(split_1[0])\n",
    "    return split_2[1]\n",
    "tmp = get_label(dataset_commands_filepaths[0])\n",
    "print ('get_label(dataset_commands_filepaths[0]):')\n",
    "print (type(tmp))\n",
    "print (tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1-3. waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_waveform(dataset_commands_filepaths[0]):\n",
      "<class 'numpy.ndarray'>\n",
      "(16000,)\n",
      "[-0.00012207  0.00390625  0.00363159 ...  0.0005188   0.00531006\n",
      "  0.00247192]\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "def get_waveform(filepath):\n",
    "    sample_rate = 16000\n",
    "    waveform, fs = librosa.load(filepath, sr=sample_rate)\n",
    "    return waveform\n",
    "tmp = get_waveform(dataset_commands_filepaths[0])\n",
    "print ('get_waveform(dataset_commands_filepaths[0]):')\n",
    "print (type(tmp))\n",
    "print (tmp.shape)\n",
    "print (tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1-4. label id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_label_id(get_label(dataset_commands_filepaths[0]):\n",
      "<class 'numpy.int64'>\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def get_label_id(label,command_list):\n",
    "    label_id = np.argmax(label==command_list)\n",
    "    return label_id\n",
    "tmp = get_label_id(get_label(dataset_commands_filepaths[0]),dataset_commands_dirslist)\n",
    "print ('get_label_id(get_label(dataset_commands_filepaths[0]):')\n",
    "print (type(tmp))\n",
    "print (tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1-5-1. MFCC-python_speech_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (4096) is greater than FFT size (2048), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_features_m(get_waveform(dataset_commands_files[0])):\n",
      "<class 'numpy.ndarray'>\n",
      "(16, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f12d4c3b2e8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import python_speech_features\n",
    "import matplotlib.pyplot as plt\n",
    "def get_features_m(waveform):\n",
    "    # Zero-padding for an audio waveform with less than 16,000 samples.\n",
    "    #input_len = 16000\n",
    "    #waveform = waveform[:input_len]\n",
    "    # np.shape(waveform) =  (16000,)\n",
    "    zero_padding = np.zeros( (16000-np.shape(waveform)[0],), dtype=np.float32)\n",
    "    # Cast the waveform tensors with np.float32\n",
    "    waveform = np.cast['float32'](waveform)\n",
    "    # Concatenate the waveform with `zero_padding`, which ensures all audio clips are of the same length.\n",
    "    equal_length = np.concatenate([waveform, zero_padding], 0)\n",
    "    \n",
    "    sample_rate = 16000\n",
    "    num_mfcc = 16\n",
    "    len_mfcc = 40\n",
    "    mfccs = python_speech_features.base.mfcc(equal_length, \n",
    "                                            samplerate=sample_rate,\n",
    "                                            winlen=0.256,\n",
    "                                            winstep=0.050,\n",
    "                                            numcep=num_mfcc,\n",
    "                                            nfilt=26,\n",
    "                                            nfft=2048,\n",
    "                                            preemph=0.0,\n",
    "                                            ceplifter=0,\n",
    "                                            appendEnergy=False,\n",
    "                                            winfunc=np.hanning)\n",
    "    return mfccs.transpose()\n",
    "tmp = get_features_m(get_waveform(dataset_commands_filepaths[0]))\n",
    "print ('get_features_m(get_waveform(dataset_commands_files[0])):')\n",
    "print (type(tmp))\n",
    "print (tmp.shape)\n",
    "#print (tmp)\n",
    "fig = plt.figure()\n",
    "plt.imshow(tmp, cmap='inferno', origin='lower')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1-5-1. MFCC-librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_features_m(get_waveform(dataset_commands_files[0])):\n",
      "<class 'numpy.ndarray'>\n",
      "(16, 32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f12d4b35be0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAADGCAYAAADL/dvjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAS8ElEQVR4nO3df4xlZ13H8c/nzp0fO7vbbtf+oNDSViQgaRBwJaIECb+CSCwaQqjBFDVijGhREgT8AzQxIYKIiQayAlpjpRIoQgxqN/wIYrTSLi39sQgUltKl3WX7a390Z2Zn7tc/7l27u53Z+33uOXfuPsP7lWzmzp1nnvM855z7nbPn3u/zdUQIAFCfzqQHAAAYDQEcACpFAAeAShHAAaBSBHAAqFR3PTd2/jmduOzCCf3NmPiHbSY+gAlyrtlG+0RUr2A+G2zqRfPJhoSpccSOcez45Ple0HT3PSsHI+KC059f1wB+2YUd3fzec9dzk4/r9Saz3dLtl7zoO8mjX9Jn29uWpE7yhbd0PN9ndk6T3EdLK+mmcSw7n4LtJ085F0SByL6MlvN9enPyGJ2zKd9pVklcyJ4j3al8n8nXxvQvP/TdVX89vyUAwNmEAA4AlSKAA0ClCOAAUCkCOABUigAOAJUigANApQjgAFApAjgAVGpdMzG10pMOHR3eriRpMpt+7YLMwWyfE07u1OwY/v5ms81mCk6d5aVcu8X8Du0dTc49m404nd+2Z3Lt0lmLUv5cKjnkybaxUPDa6I4hY3Ql12fsfyzf53JyTtn5FPCmgv051ywEcwUOAJUaGsBtf9T2Adt3rvKzt9oO2+ePZ3gAgLVkrsD/TtIrT3/S9qWSXiHp3pbHBABIGBrAI+JLkh5a5Ud/Ielt2ngLYQJAFUa6B277Kkn7IuL2RNs32b7F9i0HDxPrAaAtxW+B2p6X9E71b58MFRE7Je2UpJ+8okMEB4CWjHIF/jRJV0i63fZeSZdI2m37SW0ODABwZsVX4BFxh6QLT3w/COI7IuJgi+MCAAyR+RjhxyT9l6Rn2L7P9m+Mf1gAgGGGXoFHxNVDfn55emt2Wb24jOVk3cGSrLhs1uZ0QZ9ZRdl7E8wYXSgoepi9UXfuXL7LJ83nGq4kx3noSHrbWs7tdyczDKWCrM2SY5nd7zP5cXo2+dqYT6arFvDhxXzjuTFkaGfNFMS4hrVYycQEgEoRwAGgUgRwAKgUARwAKkUAB4BKEcABoFIEcACoFAEcACpFAAeAShHAAaBS61vU2JbmEim2S8fzfWZTiwvSmtN9luy9cRStze6mqUkXdE5uf6Yg/brb8qm7JZmaL0kLBSndSd46jgLVyYO0VLAsQlZ2iYsS5xUco+z5kd1HJW1L+kyfx6sXdOYKHAAqNVJRY9vvtf1121+z/Snb28Y6SgDAE4xa1HiXpCsj4tmSviHpHS2PCwAwxEhFjSPipog4cePsv9WvygMAWEdt3AP/dUn/utYPTylqfGgcC1MDwA+nRgHc9h9JWpZ0/VptImJnROyIiB3nn8N7pgDQlpE/i2X7jZJeLemlEdnPngEA2jJSALf9Sklvk/RzEbH6BxQBAGM1alHjv5K0VdIu27fZ/tCYxwkAOM2oRY0/MtrmIpeh1Sm4V95NZvkVZTgm7wiNIYGtKGsyW2C2ZH9mM+hKasFm9+eDh9JdxkKy7RgyYJ39f+t0wU7KnsclksWXY7HgDuhSdpz5TMxYyZ7HC+k+PZU88AX3INIFnUuOZbdZxirvKgJApQjgAFApAjgAVIoADgCVIoADQKUI4ABQKQI4AFSKAA4AlSKAA0ClCOAAUKn1LWrci1zB4uP5dcNjKbvtdJdp6ZRqSZFNu0+mP/e3n0yVXi6Y/HI2rbkg/Tp7mbCQT0GO48lOs+PsFWw723Ac+yh7fCRFbyrVzgXp3J5uP0W9k9xPMY7XcMklbLYwenbpCEnqNJsUV+AAUKlRixpvt73L9jcHX88b7zABAKcbtajx2yV9LiKeLulzg+8BAOtopKLGkq6SdN3g8XWSXtPusAAAw4x6D/yiiLh/8PgBSRet1fCUosaHqbwGAG1p/CbmoB7mmpH5lKLGW8ewaD0A/JAaNYDvt32xJA2+HmhvSACAjFED+GckXTN4fI2kT7czHABA1qhFjd8j6eW2vynpZYPvAQDraNSixpL00uKtdTrS/FyuXZJ7yUymbDupnzHasvTd/07B+wTJcab3UUGf4xinLjg/3WXMb0m189JirsOSfZQ8P2NuU7rL3vw5+e0ndR7LFX72ckF17l4ya7Okz4VjqWZF53FJIe+sleSciuaeTSVfvR2ZmABQKQI4AFSKAA4AlSKAA0ClCOAAUCkCOABUigAOAJUigANApQjgAFApAjgAVGqdixr3pCOJtNmCoqDposYlshm7BXuvpABy1jgKOsdK7m+6p0rS83Np973vPZzvc+rBVLPsfGI5VwBYknrHkwezl0tl7/eZm09625IiW6g58ssiZI97ZzqfTt7dspBql56PpFhJFnQuKCrs5Jw6s4nC7Sf6nM0XlF51W41+GwAwMY0CuO3ft32X7Tttf8x2YqUqAEAbRg7gtp8i6fck7YiIKyVNSXp9WwMDAJxZ01soXUmbbHclzUv6fvMhAQAyRg7gEbFP0vsk3SvpfkmPRsRNp7ejqDEAjEeTWyjnSbpK0hWSnixps+03nN6OosYAMB5NbqG8TNJ3IuIHEXFc0o2SfqadYQEAhmkSwO+V9NO2521b/RJre9oZFgBgmCb3wG+W9AlJuyXdMehrZ0vjAgAM0Sg/MCLeJeld6V+Y6kjnbB7erqB4qbNFQZcLMp6ymaCzBX//skVWC4oFe2uyz6WCzLB0UeOCuc9Mp5pNdfPZkFpKniPLybl3Cs6PbLbDbEFaRPq4F4wzW1w3W6y3RElh3+R+6m3PF73OFrN29vyQpKVkrBlHQeU1PuBHJiYAVIoADgCVIoADQKUI4ABQKQI4AFSKAA4AlSKAA0ClCOAAUCkCOABUigAOAJVa36LGSz3FviPD2xX8WYnFZONevtNIti0piKps24K527l05VgpSM+fzqXSl/SZTas+uveCdJeLh+dT7TrJIrzduVzqdb9tLqW6pLBvZ7ogpTvdae5Ydqbz5/HyY8m098XEkhkntp8sAjw1+0C6z/S2k8dSktzNLWPggv3p+WY1ErgCB4BKNS1qvM32J2x/3fYe2y9oa2AAgDNregvlLyX9W0S81vaM+nUxAQDrYOQAbvtcSS+S9EZJioglSfkbSgCARprcQrlC0g8k/a3tr9r+sO0nvHNxSlHjIxQ1BoC2NAngXUnPk/TBiHiupKOS3n56o1OKGm+hqDEAtKVJAL9P0n2D0mpSv7za85oPCQCQ0aQm5gOSvmf7GYOnXirp7lZGBQAYqumnUH5X0vWDT6B8W9KvNR8SACCjaVHj2yTtSP/Cphnpyqc22eQTdI4czjUsKJSsmZlUs+jmivWWyBZjlZTOcHS3/YTbknczYmY21W7LT+X2uyRtfeRArmFy7r1ztqW3HfPJ4rrLBR/K6hQUdJ6gmYXHUu1KzmMvJAs1F7w08kWVC25C9JJn/eZ8FmrMbUq2/M6qz5KJCQCVIoADQKUI4ABQKQI4AFSKAA4AlSKAA0ClCOAAUCkCOABUigAOAJUigANApda3qPHikvzt7w5tFgv5LnvHcinI2ULFfUeT286nfityabguKYSbLAarbh3rsC8f3Jpuu/TollS73kruuMdKfr9LD6darRzPv7xWlieXSm/nz4+Zzbl89qmZfJFmJ5cR6EznlmToN869NjtTyTR+SZ1Nubl3Zh9N9+nND6XbrrqtRr8NAJiYxgHc9tSgIs+/tDEgAEBOG1fg10ra00I/AIACjQK47Usk/YKkD7czHABAVtMr8A9IepukNRfbpqgxAIzHyAHc9qslHYiIW8/UjqLGADAeTa7Af1bSL9reK+kGSS+x/Q+tjAoAMFSTosbviIhLIuJySa+X9PmIeENrIwMAnBGfAweASrWSiRkRX5T0xaENZ6YVT31KG5v8f51s8dQxFDXulBSizRYWThdjlbycz3abpGzx55nHchmwkjTzwL7ctrN1hbMFayXF8dx1T28xX/Q6m1XrzfnMQY/j8izbZ8HLTdPJfb89n6kbW8/NtUsW3JYkjaGIeaRfw3ev+ixX4ABQKQI4AFSKAA4AlSKAA0ClCOAAUCkCOABUigAOAJUigANApQjgAFApAjgAVGp9ixorcunfR4/kuzx0bPThrGUluW55QR3cbFpzFKQgZ1dXd8lRnkqmNWf3kSRnU6Xn8kWilw/Opdod2Xtxqt2hB89Lb3tpMbvUQn4fdTq5FPluQdHr2fnca2N2y2PpPp2cU0mx4Km53HoHvYIi0Z7KxoV8/Ogk9/309sP5PreXrDmwyu+P+ou2L7X9Bdt3277L9rWNRgIAKNLkCnxZ0lsjYrftrZJutb0rIlZfdQUA0Kom64HfHxG7B48Pq1/YuN2lBgEAa2rlTUzbl0t6rqSb2+gPADBc4wBue4ukT0p6S0QcWuXnjxc1frTZDXsAwOMaBXDb0+oH7+sj4sbV2pxS1PhcPrUIAG1p8ikUS/qIpD0R8f72hgQAyGhalf5X1a9Gf9vg36taGhcAYIiRP0YYEV+WlC8kCABo1bpmYsbsvBZ/7CeGt5sqKDTayU0huvk+OwtPeC92VVNHH0z3mS2qnC0ALEm9uS25Pqc3p/vM7if38hmBnWMPp9pN3/T5dJ/dZ29Ptdvy6gtS7TZt/pH0tiNZzLq39cnpPrO8+Gi6bWzKzcmzuX0kSdOz5+faTeXPuaXl3Jy6d12f7rP7wL25hp38TYje/LZUu5VtP57uc7mbzT7eteqzvKsIAJUigANApQjgAFApAjgAVIoADgCVIoADQKUI4ABQKQI4AFSKAA4AlSKAA0ClHJEvvNpUxzMx3b1waLteJAofD6z0jiZblqxFnvu71l9NNylZrbgXC/k+lS0cW7JkzTjOh9z2f+W83073+JvPvC/V7rInfz/VrtvNLw3Qi/aXAOq4/f2+uJBbFuHBh/MFnR85lkuRP3hsPt3ntw7n+pwu2EcLK7nX8D1H8sfynoVcsfX9U/vTfR6L3DIC+4/+560RseP055uuB/5K2/9r+1u2396kLwBAmSbrgU9J+mtJPy/pWZKutv2stgYGADizJlfgz5f0rYj4dkQsSbpB0lXtDAsAMEyTAP4USd876fv7RFV6AFg3Y18P3PabJL2p/11uHWUAwHBNAvg+SZee9P0lg+dOERE7Je2U+p9CabA9AMBJmtxC+Yqkp9u+wvaMpNdL+kw7wwIADNOkJuay7TdL+nf17418NCLuam1kAIAzanQPPCI+K+mzLY0FAFBgXTMxbf9A0ndPe/p8SQfXbRDjt9HmI228OTGfs99Gm1PT+VwWEU+oPr2uAXw1tm9ZLUW0VhttPtLGmxPzOftttDmNaz4sZgUAlSKAA0ClzoYAvnPSA2jZRpuPtPHmxHzOfhttTmOZz8TvgQMARnM2XIEDAEZAAAeASk00gG+0ghC299q+w/Zttm+Z9HhGYfujtg/YvvOk57bb3mX7m4Ov+RIuE7bGfN5te9/gON1m+1WTHGMJ25fa/oLtu23fZfvawfNVHqMzzKfmYzRn+39s3z6Y0x8Pnr/C9s2DePdPgyVImm1rUvfABwUhviHp5eovRfsVSVdHxN0TGVALbO+VtCMiqk1AsP0iSUck/X1EXDl47s8kPRQR7xn8oT0vIv5wkuPMWmM+75Z0JCLeN8mxjcL2xZIujojdtrdKulXSayS9URUeozPM53Wq9xhZ0uaIOOJ+3cUvS7pW0h9IujEibrD9IUm3R8QHm2xrklfgFIQ4C0XElyQ9dNrTV0m6bvD4OvVfYFVYYz7Vioj7I2L34PFhSXvUX4e/ymN0hvlUK/pOFNCcHvwLSS+R9InB860co0kG8I1YECIk3WT71sE66BvFRRFx/+DxA5IumuRgWvJm218b3GKp4nbD6WxfLum5km7WBjhGp81HqvgY2Z6yfZukA5J2SbpH0iMRcaJ6divxjjcx2/XCiHie+nVCf2fw3/cNJfr33Gr/7OkHJT1N0nMk3S/pzyc6mhHY3iLpk5LeEhGHTv5ZjcdolflUfYwiYiUinqN+nYTnS3rmOLYzyQCeKghRk4jYN/h6QNKn1D9wG8H+wb3KE/csD0x4PI1ExP7BC6wn6W9U2XEa3Ff9pKTrI+LGwdPVHqPV5lP7MTohIh6R9AVJL5C0zfaJFWBbiXeTDOAbqiCE7c2DN2Fke7OkV0i688y/VY3PSLpm8PgaSZ+e4FgaOxHoBn5JFR2nwRtkH5G0JyLef9KPqjxGa82n8mN0ge1tg8eb1P+gxh71A/lrB81aOUYTzcQcfDToA3q8IMSfTmwwDdn+UfWvuqX+Ouv/WON8bH9M0ovVX/5yv6R3SfpnSR+X9FT1lwN+XURU8cbgGvN5sfr/NQ9JeyX91kn3j89qtl8o6T8k3SGpN3j6nerfN67uGJ1hPler3mP0bPXfpJxS/yL54xHxJ4MYcYOk7ZK+KukNEbHYaFuk0gNAnXgTEwAqRQAHgEoRwAGgUgRwAKgUARwAKkUAB4BKEcABoFL/BzjDsknUwxnRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import python_speech_features\n",
    "import matplotlib.pyplot as plt\n",
    "def get_features(waveform):\n",
    "    # Zero-padding for an audio waveform with less than 16,000 samples.\n",
    "    #input_len = 16000\n",
    "    #waveform = waveform[:input_len]\n",
    "    # np.shape(waveform) =  (16000,)\n",
    "    zero_padding = np.zeros( (16000-np.shape(waveform)[0],), dtype=np.float32)\n",
    "    # Cast the waveform tensors with np.float32\n",
    "    waveform = np.cast['float32'](waveform)\n",
    "    # Concatenate the waveform with `zero_padding`, which ensures all audio clips are of the same length.\n",
    "    equal_length = np.concatenate([waveform, zero_padding], 0)\n",
    "    \n",
    "    sample_rate = 16000\n",
    "    num_mfcc = 16\n",
    "    len_mfcc = 40\n",
    "    mfccs = librosa.feature.mfcc(y=equal_length, sr=sample_rate, n_mfcc=num_mfcc)\n",
    "    return mfccs\n",
    "tmp = get_features(get_waveform(dataset_commands_filepaths[0]))\n",
    "print ('get_features_m(get_waveform(dataset_commands_files[0])):')\n",
    "print (type(tmp))\n",
    "print (tmp.shape)\n",
    "#print (tmp)\n",
    "fig = plt.figure()\n",
    "plt.imshow(tmp, cmap='inferno', origin='lower')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1-6. Spectrum(optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_features(get_waveform(dataset_commands_files[0])):\n",
      "<class 'numpy.ndarray'>\n",
      "16\n",
      "(16, 32)\n",
      "[[-3.91458740e+02 -3.76576874e+02 -3.78552734e+02 -3.79463501e+02\n",
      "  -3.78944244e+02 -3.78807343e+02 -3.80264191e+02 -3.78174713e+02\n",
      "  -3.76509399e+02 -3.75415100e+02 -3.75086060e+02 -3.75339203e+02\n",
      "  -3.82617645e+02 -3.86921509e+02 -3.77693726e+02 -3.74921539e+02\n",
      "  -3.77292480e+02 -3.71453766e+02 -3.60809509e+02 -3.48729218e+02\n",
      "  -3.22807892e+02 -2.81701477e+02 -1.82798447e+02 -9.10629044e+01\n",
      "  -1.18407043e+02 -3.12057037e+02 -6.98773682e+02 -6.98773682e+02\n",
      "  -6.98773682e+02 -6.98773682e+02 -6.98773682e+02 -6.98773682e+02]\n",
      " [ 1.06693192e+02  1.10174393e+02  1.07066551e+02  1.05052567e+02\n",
      "   1.03247559e+02  1.02217216e+02  1.05683609e+02  1.10246521e+02\n",
      "   1.09678963e+02  1.06813164e+02  1.02934738e+02  1.05858757e+02\n",
      "   1.03071510e+02  1.02274033e+02  1.08146324e+02  1.10282982e+02\n",
      "   1.12189117e+02  1.19153610e+02  1.22209457e+02  1.12225311e+02\n",
      "   1.10557083e+02  1.46357788e+02  1.95780121e+02  1.64607574e+02\n",
      "   1.44947937e+02  1.28990082e+02  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-1.63310528e+01 -2.14831429e+01 -2.43852768e+01 -2.18035355e+01\n",
      "  -2.82670517e+01 -3.20819969e+01 -2.91519012e+01 -2.54890289e+01\n",
      "  -2.83755665e+01 -3.27486916e+01 -3.27074509e+01 -2.79362411e+01\n",
      "  -2.64658928e+01 -2.15910721e+01 -2.23150291e+01 -3.02448807e+01\n",
      "  -2.98268242e+01 -2.64682560e+01 -3.40287170e+01 -4.46635857e+01\n",
      "  -6.18060379e+01 -5.25738754e+01 -6.86024780e+01 -5.68932037e+01\n",
      "  -5.18653259e+01 -3.74254341e+01  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-9.77669716e+00 -1.69720459e+01 -1.85605774e+01 -1.79237614e+01\n",
      "  -2.04734764e+01 -1.92800312e+01 -1.78642921e+01 -1.41180449e+01\n",
      "  -1.63943806e+01 -2.44121590e+01 -2.49111671e+01 -1.87638283e+01\n",
      "  -1.63414841e+01 -8.82377434e+00 -1.20991859e+01 -1.57947140e+01\n",
      "  -1.88926010e+01 -2.06384277e+01 -2.08983727e+01 -1.30061321e+01\n",
      "  -5.30738783e+00  6.96071720e+00 -1.68134918e+01 -3.36307487e+01\n",
      "  -4.04945068e+01 -4.24442215e+01  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 1.20988235e+01  1.00339155e+01  8.89910126e+00  5.86188841e+00\n",
      "   7.59086561e+00  1.18843794e+01  5.63194942e+00  5.75872421e+00\n",
      "   9.66348457e+00  7.59632540e+00  9.77680492e+00  9.47515488e+00\n",
      "   1.02581539e+01  1.30843029e+01  8.78899193e+00  1.13471241e+01\n",
      "   1.13825979e+01  1.20619926e+01  2.25709190e+01  2.43561649e+01\n",
      "   2.66875114e+01  3.85858383e+01  4.12711411e+01  2.64787540e+01\n",
      "   1.61980247e+01  1.17353213e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 1.34650211e+01  1.59583178e+01  1.75784454e+01  1.97290878e+01\n",
      "   1.95861073e+01  1.97811241e+01  2.06817818e+01  1.92753754e+01\n",
      "   1.59469337e+01  1.60050049e+01  1.72999649e+01  1.85621433e+01\n",
      "   1.79578133e+01  1.59939661e+01  1.45094995e+01  1.85308914e+01\n",
      "   1.93621311e+01  1.67534065e+01  2.11510353e+01  1.62336006e+01\n",
      "   6.70462906e-01  9.31145787e-01 -8.19456482e+00 -3.47683549e-01\n",
      "   6.04279327e+00  9.61476135e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-1.30350518e+00 -1.47385454e+00 -1.62569225e+00 -2.97667980e-02\n",
      "   4.84185636e-01  1.20724833e+00  1.42141581e+00  2.20136523e+00\n",
      "   3.07847929e+00 -9.41578209e-01 -3.16912055e+00  7.35871971e-01\n",
      "   1.17495954e-01 -3.76780152e+00 -3.73958898e+00 -2.83309317e+00\n",
      "  -4.95946109e-01 -1.86906433e+00 -6.76335239e+00 -1.25486317e+01\n",
      "  -2.07166595e+01 -2.86541176e+01 -3.68420677e+01 -3.14065285e+01\n",
      "  -2.26869717e+01 -1.01382008e+01  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-3.70445037e+00 -6.05193138e+00 -7.22384596e+00 -4.99672461e+00\n",
      "  -7.01182270e+00 -8.70288658e+00 -2.49563646e+00 -4.09282875e+00\n",
      "  -2.60074854e+00 -7.29053164e+00 -7.05023289e+00 -5.98159027e+00\n",
      "  -1.02443419e+01 -1.41075754e+01 -1.20874710e+01 -1.17011738e+01\n",
      "  -1.26553755e+01 -1.14857273e+01 -1.87678471e+01 -2.18417740e+01\n",
      "  -1.47589970e+01 -1.44862251e+01 -7.01853991e+00 -6.45808887e+00\n",
      "  -4.75736427e+00 -1.75192094e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-6.24846363e+00 -9.01745987e+00 -1.03829346e+01 -1.03668060e+01\n",
      "  -1.15347204e+01 -1.29234219e+01 -1.10304928e+01 -8.96389771e+00\n",
      "  -5.97062635e+00 -6.81536484e+00 -1.10791473e+01 -1.08573380e+01\n",
      "  -1.19964638e+01 -1.29746857e+01 -1.08425694e+01 -1.16237602e+01\n",
      "  -1.17306252e+01 -1.18148088e+01 -1.05367813e+01 -4.38372803e+00\n",
      "   7.54767299e-01 -3.54529381e+00 -3.16745430e-01  9.63532257e+00\n",
      "   1.33203697e+01  1.66223660e+01  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 2.13532581e+01  1.08756952e+01  2.25556707e+00 -2.38635159e+00\n",
      "  -4.33184147e-01  2.45868683e+00 -1.67309523e+00 -7.17833042e+00\n",
      "  -3.50902152e+00  4.28995800e+00  5.66665459e+00  6.69337225e+00\n",
      "   2.93599892e+00  2.36871099e+00  6.50801277e+00  8.31716919e+00\n",
      "   1.06980057e+01  5.84864044e+00  6.95407295e+00  1.18823490e+01\n",
      "   1.36372890e+01  8.57755089e+00  1.47399056e+00  1.60214186e+00\n",
      "   4.33010674e+00  1.13788891e+01  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 1.51389017e+01  6.77957821e+00 -3.10097456e-01 -2.78461242e+00\n",
      "  -2.34384823e+00 -3.67333472e-01 -4.84011471e-01  1.48243678e+00\n",
      "   3.41426778e+00  3.14880013e-01  1.69707596e+00  3.54173350e+00\n",
      "   3.18485308e+00  2.72831082e+00  4.32919788e+00  2.14048219e+00\n",
      "   3.39157176e+00  2.66730714e+00 -2.20672464e+00 -1.13196001e+01\n",
      "  -8.35940266e+00 -2.52294970e+00 -1.38835323e+00 -4.03230619e+00\n",
      "  -6.76229954e+00 -7.46842718e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-5.78117752e+00 -7.05890083e+00 -7.01205349e+00 -7.10503006e+00\n",
      "  -3.46840262e+00 -2.60576105e+00 -3.04066968e+00 -1.82394314e+00\n",
      "  -2.00839663e+00 -3.26114893e-01 -7.68437445e-01 -1.75696182e+00\n",
      "  -1.17188323e+00 -1.33514845e+00  2.12217331e-01 -2.75147152e+00\n",
      "  -1.88899291e+00 -1.37381232e+00 -1.67954445e+00  2.73795784e-01\n",
      "  -1.37054563e+00 -6.85463810e+00 -6.74111509e+00 -5.52548409e+00\n",
      "  -6.87027502e+00 -1.11071892e+01  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-1.87239189e+01 -1.30586586e+01 -1.22614765e+01 -1.98683720e+01\n",
      "  -1.70405464e+01 -1.10832214e+01 -8.86666870e+00 -9.84899139e+00\n",
      "  -1.31667414e+01 -1.40960655e+01 -1.31651659e+01 -1.16676941e+01\n",
      "  -1.04965849e+01 -5.75165510e+00 -6.59328032e+00 -8.25127506e+00\n",
      "  -3.87254047e+00 -5.66539240e+00 -2.18370247e+00  6.41358376e-01\n",
      "  -8.40734768e+00 -1.42973061e+01 -1.00131683e+01 -7.43783045e+00\n",
      "  -3.92702174e+00  4.34259057e-01  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-6.08103895e+00  6.64187551e-01  6.24799538e+00  2.15796089e+00\n",
      "  -1.34297216e+00 -3.04483557e+00 -1.54339814e+00  2.16033697e-01\n",
      "  -2.12650728e+00 -2.14655304e+00 -5.64024067e+00 -4.79058552e+00\n",
      "  -2.12569046e+00  8.33988190e-01  6.33544326e-01 -1.51421726e+00\n",
      "   3.20556343e-01 -7.77082622e-01  3.78241348e+00  2.43906713e+00\n",
      "  -6.21626854e+00 -6.22536039e+00 -8.00826454e+00 -2.95172358e+00\n",
      "   2.86525774e+00  1.08473873e+01  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 3.36295986e+00  2.00741625e+00  2.11797643e+00  8.39435959e+00\n",
      "   7.84233761e+00 -2.51476645e-01 -3.39030528e+00 -2.95531297e+00\n",
      "   3.84392309e+00  7.41986334e-02 -3.82006955e+00  4.40275073e-01\n",
      "   6.76382637e+00  7.08985806e+00  3.67916083e+00 -1.78434873e+00\n",
      "   2.71433473e-01  4.05817604e+00 -4.05802345e+00 -5.91306305e+00\n",
      "  -5.30272961e+00 -9.46104622e+00 -8.26451302e+00 -2.38184482e-01\n",
      "   6.85708332e+00  8.36227703e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 9.79375553e+00  5.27993536e+00  5.96202660e+00  8.05925560e+00\n",
      "   9.80138969e+00  9.89257431e+00  8.41164207e+00  7.43881989e+00\n",
      "   5.83962727e+00  1.48039019e+00  3.21223497e+00  3.87727261e+00\n",
      "   2.00164056e+00  1.90102577e+00  4.70639229e+00  5.25235271e+00\n",
      "   5.40130711e+00  5.05788231e+00  1.28310609e+00  3.02499247e+00\n",
      "   9.15251637e+00  1.42257833e+00 -7.41112518e+00 -2.14819264e+00\n",
      "   4.36704922e+00  1.30129158e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f12d4aa3f60>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import python_speech_features\n",
    "import matplotlib.pyplot as plt\n",
    "def get_features_s(waveform):\n",
    "    # Zero-padding for an audio waveform with less than 16,000 samples.\n",
    "    #input_len = 16000\n",
    "    #waveform = waveform[:input_len]\n",
    "    # np.shape(waveform) =  (16000,)\n",
    "    zero_padding = np.zeros( (16000-np.shape(waveform)[0],), dtype=np.float32)\n",
    "    # Cast the waveform tensors with np.float32\n",
    "    waveform = np.cast['float32'](waveform)\n",
    "    # Concatenate the waveform with `zero_padding`, which ensures all audio clips are of the same length.\n",
    "    equal_length = np.concatenate([waveform, zero_padding], 0)\n",
    "    \n",
    "    sample_rate = 16000\n",
    "    num_mfcc = 16\n",
    "    len_mfcc = 40\n",
    "    spectrum = np.abs(librosa.stft(equal_length,512))\n",
    "    return spectrum.transpose()\n",
    "tmp = get_features(get_waveform(dataset_commands_filepaths[5000]))\n",
    "print ('get_features(get_waveform(dataset_commands_files[0])):')\n",
    "print (type(tmp))\n",
    "print (len(tmp))\n",
    "print (tmp.shape)\n",
    "print (tmp)\n",
    "fig = plt.figure()\n",
    "plt.imshow(tmp, cmap='inferno', origin='lower')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2. Preporcess set commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_val = []\n",
    "y_val = []\n",
    "x_test = []\n",
    "y_test = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2-1. get set command filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_commands_dir: ./data_speech_commands_v002/yes/*\n",
      "file num : 4044\n",
      "-\n",
      "set_commands_dir: ./data_speech_commands_v002/no/*\n",
      "file num : 3941\n",
      "-\n",
      "set_commands_dir: ./data_speech_commands_v002/on/*\n",
      "file num : 3845\n",
      "-\n",
      "set_commands_dir: ./data_speech_commands_v002/off/*\n",
      "file num : 3745\n",
      "-\n",
      "num of train_set_commands_filepaths: 12459\n",
      "num of val_set_commands_filepaths: 1556\n",
      "num of test_set_commands_filepaths: 1560\n",
      "total of set_commands_filepaths: 15575\n",
      "sample of train_set_commands_filepaths: ./data_speech_commands_v002/yes/cd671b5f_nohash_0.wav\n"
     ]
    }
   ],
   "source": [
    "train_set_commands_filepaths = []\n",
    "val_set_commands_filepaths = []\n",
    "test_set_commands_filepaths = []\n",
    "set_commands_dirslist = commands\n",
    "for item in set_commands_dirslist:\n",
    "    set_commands_dir = os.path.join(dataset_path, item,'*')\n",
    "    print('set_commands_dir:', set_commands_dir)\n",
    "    \n",
    "    fileslist = tf.io.gfile.glob(set_commands_dir)\n",
    "    random.shuffle(fileslist)\n",
    "    print('file num :', len(fileslist))\n",
    "    \n",
    "    train, val, test = get_split_num(0.8, 0.1, 0.1, len(fileslist))\n",
    "    train_set_commands_filepaths.extend(fileslist[:val])\n",
    "    val_set_commands_filepaths.extend(fileslist[val:test])\n",
    "    test_set_commands_filepaths.extend(fileslist[test:])\n",
    "    \n",
    "    print('-')\n",
    "print('num of train_set_commands_filepaths:', len(train_set_commands_filepaths))\n",
    "print('num of val_set_commands_filepaths:', len(val_set_commands_filepaths))\n",
    "print('num of test_set_commands_filepaths:', len(test_set_commands_filepaths))\n",
    "total_set_commands_num = len(train_set_commands_filepaths)+len(val_set_commands_filepaths)+len(test_set_commands_filepaths)\n",
    "print('total of set_commands_filepaths:',total_set_commands_num)\n",
    "print('sample of train_set_commands_filepaths:', train_set_commands_filepaths[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2-2. get MFCCs and label id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of train_set_commands_features: 12459\n",
      "num of train_set_commands_label_id: 12459\n",
      "-\n",
      "num of val_set_commands_features: 1556\n",
      "num of val_set_commands_label_id: 1556\n",
      "-\n",
      "num of test_set_commands_features: 1560\n",
      "num of test_set_commands_label_id: 1560\n"
     ]
    }
   ],
   "source": [
    "train_set_commands_features = []\n",
    "val_set_commands_features = []\n",
    "test_set_commands_features = []\n",
    "\n",
    "train_set_commands_label_id = []\n",
    "val_set_commands_label_id = []\n",
    "test_set_commands_label_id = []\n",
    "\n",
    "convert_num = 1000000\n",
    "\n",
    "for i, item in enumerate(train_set_commands_filepaths):\n",
    "    if i<convert_num:\n",
    "        waveform = get_waveform(item)\n",
    "        features = get_features(waveform)\n",
    "        train_set_commands_features.append(features)\n",
    "        \n",
    "        label = get_label(item)\n",
    "        label_id = get_label_id(label,commands)\n",
    "        train_set_commands_label_id.append(label_id)\n",
    "\n",
    "for i, item in enumerate(val_set_commands_filepaths):\n",
    "    if i<convert_num:\n",
    "        waveform = get_waveform(item)\n",
    "        features = get_features(waveform)\n",
    "        val_set_commands_features.append(features)\n",
    "        \n",
    "        label = get_label(item)\n",
    "        label_id = get_label_id(label,commands)\n",
    "        val_set_commands_label_id.append(label_id)\n",
    "        \n",
    "for i, item in enumerate(test_set_commands_filepaths):\n",
    "    if i<convert_num:\n",
    "        waveform = get_waveform(item)\n",
    "        features = get_features(waveform)\n",
    "        test_set_commands_features.append(features)\n",
    "        \n",
    "        label = get_label(item)\n",
    "        label_id = get_label_id(label,commands)\n",
    "        test_set_commands_label_id.append(label_id)        \n",
    "        \n",
    "\n",
    "print ('num of train_set_commands_features:', len(train_set_commands_features))\n",
    "print ('num of train_set_commands_label_id:', len(train_set_commands_label_id))\n",
    "print('-')\n",
    "print ('num of val_set_commands_features:', len(val_set_commands_features))\n",
    "print ('num of val_set_commands_label_id:', len(val_set_commands_label_id))\n",
    "print('-')\n",
    "print ('num of test_set_commands_features:', len(test_set_commands_features))\n",
    "print ('num of test_set_commands_label_id:', len(test_set_commands_label_id)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2-3. add features and label id to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of x_train: 12459\n",
      "num of y_train: 12459\n",
      "-\n",
      "num of x_val: 1556\n",
      "num of y_val: 1556\n",
      "-\n",
      "num of x_test: 1560\n",
      "num of y_test: 1560\n"
     ]
    }
   ],
   "source": [
    "x_train.extend(train_set_commands_features)\n",
    "y_train.extend(train_set_commands_label_id)\n",
    "x_val.extend(val_set_commands_features)\n",
    "y_val.extend(val_set_commands_label_id)\n",
    "x_test.extend(test_set_commands_features)\n",
    "y_test.extend(test_set_commands_label_id)\n",
    "\n",
    "print('num of x_train:',len(y_train))\n",
    "print('num of y_train:',len(y_train))\n",
    "print('-')\n",
    "print('num of x_val:',len(x_val))\n",
    "print('num of y_val:',len(y_val))\n",
    "print('-')\n",
    "print('num of x_test:',len(x_test))\n",
    "print('num of y_test:',len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-3. Preporcess unknown commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3-1. get unknown command filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "commands: ['yes' 'no' 'on' 'off' 'unknown']\n",
      "-\n",
      "unknown_commands_dirslist: ['backward' 'bed' 'bird' 'cat' 'dog' 'down' 'eight' 'five' 'follow'\n",
      " 'forward' 'four' 'go' 'happy' 'house' 'learn' 'left' 'marvin' 'nine'\n",
      " 'one' 'right' 'seven' 'sheila' 'six' 'stop' 'three' 'tree' 'two' 'up'\n",
      " 'visual' 'wow' 'zero']\n",
      "-\n",
      "each_command: 3893\n",
      "each_unknown_command: 100\n",
      "-\n",
      "unknown_commands_dir: ./data_speech_commands_v002/backward/*\n",
      "file num : 1664\n",
      "-\n",
      "unknown_commands_dir: ./data_speech_commands_v002/bed/*\n",
      "file num : 2014\n",
      "-\n",
      "unknown_commands_dir: ./data_speech_commands_v002/bird/*\n",
      "file num : 2064\n",
      "-\n",
      "unknown_commands_dir: ./data_speech_commands_v002/cat/*\n",
      "file num : 2031\n",
      "-\n",
      "unknown_commands_dir: ./data_speech_commands_v002/dog/*\n",
      "file num : 2128\n",
      "-\n",
      "unknown_commands_dir: ./data_speech_commands_v002/down/*\n",
      "file num : 3917\n",
      "-\n",
      "unknown_commands_dir: ./data_speech_commands_v002/eight/*\n",
      "file num : 3787\n",
      "-\n",
      "unknown_commands_dir: ./data_speech_commands_v002/five/*\n",
      "file num : 4052\n",
      "-\n",
      "unknown_commands_dir: ./data_speech_commands_v002/follow/*\n",
      "file num : 1579\n",
      "-\n",
      "unknown_commands_dir: ./data_speech_commands_v002/forward/*\n",
      "file num : 1557\n",
      "-\n",
      "unknown_commands_dir: ./data_speech_commands_v002/four/*\n",
      "file num : 3728\n",
      "-\n",
      "unknown_commands_dir: ./data_speech_commands_v002/go/*\n",
      "file num : 3880\n",
      "-\n",
      "unknown_commands_dir: ./data_speech_commands_v002/happy/*\n",
      "file num : 2054\n",
      "-\n",
      "unknown_commands_dir: ./data_speech_commands_v002/house/*\n",
      "file num : 2113\n",
      "-\n",
      "unknown_commands_dir: ./data_speech_commands_v002/learn/*\n",
      "file num : 1575\n",
      "-\n",
      "unknown_commands_dir: ./data_speech_commands_v002/left/*\n",
      "file num : 3801\n",
      "-\n",
      "unknown_commands_dir: ./data_speech_commands_v002/marvin/*\n",
      "file num : 2100\n",
      "-\n",
      "unknown_commands_dir: ./data_speech_commands_v002/nine/*\n",
      "file num : 3934\n",
      "-\n",
      "unknown_commands_dir: ./data_speech_commands_v002/one/*\n",
      "file num : 3890\n",
      "-\n",
      "unknown_commands_dir: ./data_speech_commands_v002/right/*\n",
      "file num : 3778\n",
      "-\n",
      "unknown_commands_dir: ./data_speech_commands_v002/seven/*\n",
      "file num : 3998\n",
      "-\n",
      "unknown_commands_dir: ./data_speech_commands_v002/sheila/*\n",
      "file num : 2022\n",
      "-\n",
      "unknown_commands_dir: ./data_speech_commands_v002/six/*\n",
      "file num : 3860\n",
      "-\n",
      "unknown_commands_dir: ./data_speech_commands_v002/stop/*\n",
      "file num : 3872\n",
      "-\n",
      "unknown_commands_dir: ./data_speech_commands_v002/three/*\n",
      "file num : 3727\n",
      "-\n",
      "unknown_commands_dir: ./data_speech_commands_v002/tree/*\n",
      "file num : 1759\n",
      "-\n",
      "unknown_commands_dir: ./data_speech_commands_v002/two/*\n",
      "file num : 3880\n",
      "-\n",
      "unknown_commands_dir: ./data_speech_commands_v002/up/*\n",
      "file num : 3723\n",
      "-\n",
      "unknown_commands_dir: ./data_speech_commands_v002/visual/*\n",
      "file num : 1592\n",
      "-\n",
      "unknown_commands_dir: ./data_speech_commands_v002/wow/*\n",
      "file num : 2123\n",
      "-\n",
      "unknown_commands_dir: ./data_speech_commands_v002/zero/*\n",
      "file num : 4052\n",
      "-\n",
      "num of train_unknown_commands_filepaths: 2480\n",
      "num of val_unknown_commands_filepaths: 310\n",
      "num of test_unknown_commands_filepaths: 310\n",
      "sample of train_unknown_commands_filepaths: ./data_speech_commands_v002/backward/8dc18a75_nohash_3.wav\n"
     ]
    }
   ],
   "source": [
    "train_unknown_commands_filepaths = []\n",
    "val_unknown_commands_filepaths = []\n",
    "test_unknown_commands_filepaths = []\n",
    "\n",
    "if not np.any(commands=='unknown'):\n",
    "    commands = np.append(commands,'unknown')\n",
    "print ('commands:',commands)\n",
    "print('-')\n",
    "\n",
    "unknown_commands_dirslist = np.setdiff1d( dataset_commands_dirslist , commands)\n",
    "print ('unknown_commands_dirslist:',unknown_commands_dirslist)\n",
    "print('-')\n",
    "\n",
    "each_command = total_set_commands_num//len(set_commands_dirslist)\n",
    "print ('each_command:', each_command)\n",
    "each_unknown_command = each_command//len(unknown_commands_dirslist)\n",
    "each_unknown_command = 100\n",
    "print ('each_unknown_command:', each_unknown_command)\n",
    "print('-')\n",
    "\n",
    "for item in unknown_commands_dirslist:\n",
    "    unknown_commands_dir = os.path.join(dataset_path, item,'*')\n",
    "    print('unknown_commands_dir:', unknown_commands_dir)\n",
    "    \n",
    "    fileslist = tf.io.gfile.glob(unknown_commands_dir)\n",
    "    random.shuffle(fileslist)\n",
    "    print('file num :', len(fileslist))\n",
    "    \n",
    "    train, val, test = get_split_num(0.8, 0.1, 0.1, each_unknown_command)\n",
    "    train_unknown_commands_filepaths.extend(fileslist[:val])\n",
    "    val_unknown_commands_filepaths.extend(fileslist[val:test])\n",
    "    test_unknown_commands_filepaths.extend(fileslist[test:each_unknown_command])\n",
    "    print('-')\n",
    "    \n",
    "print('num of train_unknown_commands_filepaths:', len(train_unknown_commands_filepaths))\n",
    "print('num of val_unknown_commands_filepaths:', len(val_unknown_commands_filepaths))\n",
    "print('num of test_unknown_commands_filepaths:', len(test_unknown_commands_filepaths))\n",
    "print('sample of train_unknown_commands_filepaths:', train_unknown_commands_filepaths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3-2. get MFCC and label id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of train_unknown_commands_features: 2480\n",
      "num of train_unknown_commands_label_id: 2480\n",
      "-\n",
      "num of val_unknown_commands_features: 310\n",
      "num of val_unknown_commands_label_id: 310\n",
      "-\n",
      "num of test_unknown_commands_features: 310\n",
      "num of test_unknown_commands_label_id: 310\n"
     ]
    }
   ],
   "source": [
    "train_unknown_commands_features = []\n",
    "val_unknown_commands_features = []\n",
    "test_unknown_commands_features = []\n",
    "\n",
    "train_unknown_commands_label_id = []\n",
    "val_unknown_commands_label_id = []\n",
    "test_unknown_commands_label_id = []\n",
    "\n",
    "convert_num = 100000\n",
    "\n",
    "label = 'unknown'\n",
    "\n",
    "for i, item in enumerate(train_unknown_commands_filepaths):\n",
    "    if i<convert_num:\n",
    "        waveform = get_waveform(item)\n",
    "        features = get_features(waveform)\n",
    "        train_unknown_commands_features.append(features)\n",
    "       \n",
    "        label_id = get_label_id(label,commands)\n",
    "        train_unknown_commands_label_id.append(label_id)\n",
    "\n",
    "for i, item in enumerate(val_unknown_commands_filepaths):\n",
    "    if i<convert_num:\n",
    "        waveform = get_waveform(item)\n",
    "        features = get_features(waveform)\n",
    "        val_unknown_commands_features.append(features)\n",
    "\n",
    "        label_id = get_label_id(label,commands)\n",
    "        val_unknown_commands_label_id.append(label_id)\n",
    "        \n",
    "for i, item in enumerate(test_unknown_commands_filepaths):\n",
    "    if i<convert_num:\n",
    "        waveform = get_waveform(item)\n",
    "        features = get_features(waveform)\n",
    "        test_unknown_commands_features.append(features)\n",
    "\n",
    "        label_id = get_label_id(label,commands)\n",
    "        test_unknown_commands_label_id.append(label_id)        \n",
    "        \n",
    "\n",
    "print ('num of train_unknown_commands_features:', len(train_unknown_commands_features))\n",
    "print ('num of train_unknown_commands_label_id:', len(train_unknown_commands_label_id))\n",
    "print('-')\n",
    "print ('num of val_unknown_commands_features:', len(val_unknown_commands_features))\n",
    "print ('num of val_unknown_commands_label_id:', len(val_unknown_commands_label_id))\n",
    "print('-')\n",
    "print ('num of test_unknown_commands_features:', len(test_unknown_commands_features))\n",
    "print ('num of test_unknown_commands_label_id:', len(test_unknown_commands_label_id)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3-3. add features and label id to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of x_train: 14939\n",
      "num of y_train: 14939\n",
      "-\n",
      "num of x_val: 1866\n",
      "num of y_val: 1866\n",
      "-\n",
      "num of x_test: 1870\n",
      "num of y_test: 1870\n"
     ]
    }
   ],
   "source": [
    "x_train.extend(train_unknown_commands_features)\n",
    "y_train.extend(train_unknown_commands_label_id)\n",
    "x_val.extend(val_unknown_commands_features)\n",
    "y_val.extend(val_unknown_commands_label_id)\n",
    "x_test.extend(test_unknown_commands_features)\n",
    "y_test.extend(test_unknown_commands_label_id)\n",
    "\n",
    "print('num of x_train:',len(x_train))\n",
    "print('num of y_train:',len(y_train))\n",
    "print('-')\n",
    "print('num of x_val:',len(x_val))\n",
    "print('num of y_val:',len(y_val))\n",
    "print('-')\n",
    "print('num of x_test:',len(x_test))\n",
    "print('num of y_test:',len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-4. Preporcess slience command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4-1. get background command filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "commands: ['yes' 'no' 'on' 'off' 'unknown' 'slience']\n",
      "-\n",
      "slience_commands_dirslist: ['_background_noise_']\n",
      "-\n",
      "total_set_commands_num: 15575\n",
      "slience_command_num: 3115\n",
      "-\n",
      "slience_commands_dir: ./data_speech_commands_v002/_background_noise_/*.wav\n",
      "file num : 6\n",
      "each_slience_files: 519\n",
      "-\n",
      "num of train_slience_commands_filepaths: 2490\n",
      "num of val_slience_commands_filepaths: 306\n",
      "num of test_slience_commands_filepaths: 306\n",
      "sample of train_slience_commands_filepaths: ./data_speech_commands_v002/_background_noise_/dude_miaowing.wav\n"
     ]
    }
   ],
   "source": [
    "train_slience_commands_filepaths = []\n",
    "val_slience_commands_filepaths = []\n",
    "test_slience_commands_filepaths = []\n",
    "\n",
    "if not np.any(commands=='slience'):\n",
    "    commands = np.append(commands,'slience')\n",
    "print ('commands:',commands)\n",
    "print('-')\n",
    "\n",
    "slience_commands_dirslist = ['_background_noise_']\n",
    "print ('slience_commands_dirslist:',slience_commands_dirslist)\n",
    "print('-')\n",
    "\n",
    "print ('total_set_commands_num:', total_set_commands_num)\n",
    "slience_ratio = 0.2\n",
    "slience_command_num = int(total_set_commands_num * slience_ratio)\n",
    "print ('slience_command_num:', slience_command_num)\n",
    "print('-')\n",
    "\n",
    "for item in slience_commands_dirslist:\n",
    "    slience_commands_dir = os.path.join(dataset_path, item,'*.wav')\n",
    "    print('slience_commands_dir:', slience_commands_dir)\n",
    "    \n",
    "    fileslist = tf.io.gfile.glob(slience_commands_dir)\n",
    "    print('file num :', len(fileslist))\n",
    "    \n",
    "    each_slience_files = slience_command_num//len(fileslist)\n",
    "    print ('each_slience_files:', each_slience_files)\n",
    "  \n",
    "    train_num = int(each_slience_files*0.8)\n",
    "    val_num = int(each_slience_files*0.1)\n",
    "    test_num = int(each_slience_files*0.1)\n",
    "    print('-')\n",
    "    \n",
    "    for itme in fileslist:\n",
    "        for i in range(train_num):\n",
    "            train_slience_commands_filepaths.append(itme)\n",
    "        for i in range(val_num):\n",
    "            val_slience_commands_filepaths.append(itme)\n",
    "        for i in range(test_num):\n",
    "            test_slience_commands_filepaths.append(itme)\n",
    "\n",
    "print('num of train_slience_commands_filepaths:', len(train_slience_commands_filepaths))\n",
    "print('num of val_slience_commands_filepaths:', len(val_slience_commands_filepaths))\n",
    "print('num of test_slience_commands_filepaths:', len(test_slience_commands_filepaths))\n",
    "print('sample of train_slience_commands_filepaths:', train_slience_commands_filepaths[0])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4-2. contruct slience features and label id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of train_slience_commands_features: 2490\n",
      "num of train_slience_commands_label_id: 2490\n",
      "-\n",
      "num of val_slience_commands_features: 306\n",
      "num of val_slience_commands_label_id: 306\n",
      "-\n",
      "num of test_slience_commands_features: 306\n",
      "num of test_slience_commands_label_id: 306\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(66)\n",
    "\n",
    "train_slience_commands_features = []\n",
    "val_slience_commands_features = []\n",
    "test_slience_commands_features = []\n",
    "\n",
    "train_slience_commands_label_id = []\n",
    "val_slience_commands_label_id = []\n",
    "test_slience_commands_label_id = []\n",
    "\n",
    "label = 'slience'\n",
    "\n",
    "for i, item in enumerate(train_slience_commands_filepaths):\n",
    "    #print('slience_commands_filepath:',item)\n",
    "    waveform = get_waveform(item)\n",
    "    waveform_len = waveform.shape[0]\n",
    "    waveform_s = waveform_len/16000\n",
    "\n",
    "    split_start_time = random.randrange(0, waveform_len)\n",
    "    waveform_split = waveform[split_start_time:split_start_time+16000]\n",
    "    waveform_split_len = waveform_split.shape[0]\n",
    "    waveform_split_s = waveform_split_len/16000\n",
    "  \n",
    "    features = get_features(waveform_split)\n",
    "    train_slience_commands_features.append(features)\n",
    "\n",
    "    label_id = get_label_id(label,commands)\n",
    "    train_slience_commands_label_id.append(label_id)\n",
    "\n",
    "for i, item in enumerate(val_slience_commands_filepaths):\n",
    "\n",
    "    waveform = get_waveform(item)\n",
    "    waveform_len = waveform.shape[0]\n",
    "    waveform_s = waveform_len/16000\n",
    "\n",
    "    split_start_time = random.randrange(0, waveform_len)\n",
    "    waveform_split = waveform[split_start_time:split_start_time+16000]\n",
    "    waveform_split_len = waveform_split.shape[0]\n",
    "    waveform_split_s = waveform_split_len/16000\n",
    "  \n",
    "    features = get_features(waveform_split)\n",
    "    val_slience_commands_features.append(features)\n",
    "\n",
    "    label_id = get_label_id(label,commands)\n",
    "    val_slience_commands_label_id.append(label_id)    \n",
    "\n",
    "for i, item in enumerate(test_slience_commands_filepaths):\n",
    "\n",
    "    waveform = get_waveform(item)\n",
    "    waveform_len = waveform.shape[0]\n",
    "    waveform_s = waveform_len/16000\n",
    "\n",
    "    split_start_time = random.randrange(0, waveform_len)\n",
    "    waveform_split = waveform[split_start_time:split_start_time+16000]\n",
    "    waveform_split_len = waveform_split.shape[0]\n",
    "    waveform_split_s = waveform_split_len/16000\n",
    "  \n",
    "    features = get_features(waveform_split)\n",
    "    test_slience_commands_features.append(features)\n",
    "\n",
    "    label_id = get_label_id(label,commands)\n",
    "    test_slience_commands_label_id.append(label_id)    \n",
    "    \n",
    "print ('num of train_slience_commands_features:', len(train_slience_commands_features))\n",
    "print ('num of train_slience_commands_label_id:', len(train_slience_commands_label_id))\n",
    "print('-')\n",
    "print ('num of val_slience_commands_features:', len(val_slience_commands_features))\n",
    "print ('num of val_slience_commands_label_id:', len(val_slience_commands_label_id))\n",
    "print('-')\n",
    "print ('num of test_slience_commands_features:', len(test_slience_commands_features))\n",
    "print ('num of test_slience_commands_label_id:', len(test_slience_commands_label_id)) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4-3. add features and label id to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of x_train: 17429\n",
      "num of y_train: 17429\n",
      "-\n",
      "num of x_val: 2172\n",
      "num of y_val: 2172\n",
      "-\n",
      "num of x_test: 2176\n",
      "num of y_test: 2176\n"
     ]
    }
   ],
   "source": [
    "x_train.extend(train_slience_commands_features)\n",
    "y_train.extend(train_slience_commands_label_id)\n",
    "x_val.extend(val_slience_commands_features)\n",
    "y_val.extend(val_slience_commands_label_id)\n",
    "x_test.extend(test_slience_commands_features)\n",
    "y_test.extend(test_slience_commands_label_id)\n",
    "\n",
    "print('num of x_train:',len(x_train))\n",
    "print('num of y_train:',len(y_train))\n",
    "print('-')\n",
    "print('num of x_val:',len(x_val))\n",
    "print('num of y_val:',len(y_val))\n",
    "print('-')\n",
    "print('num of x_test:',len(x_test))\n",
    "print('num of y_test:',len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''''''\n",
    "feature_sets_file = 'all_targets_mfcc_sets.npz'\n",
    "# Save features and truth vector (y) sets to disk\n",
    "np.savez(feature_sets_file, \n",
    "         x_train=x_train, \n",
    "         y_train=y_train, \n",
    "         x_val=x_val, \n",
    "         y_val=y_val, \n",
    "         x_test=x_test, \n",
    "         y_test=y_test)\n",
    "''''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfeature_sets_path = './'\\nfeature_sets_filename = 'all_targets_mfcc_sets.npz'\\n# Load feature sets\\nfeature_sets = np.load(os.path.join(feature_sets_path, feature_sets_filename))\\nprint(feature_sets.files)\\n# Assign feature sets\\nx_train = feature_sets['x_train']\\ny_train = feature_sets['y_train']\\nx_val = feature_sets['x_val']\\ny_val = feature_sets['y_val']\\nx_test = feature_sets['x_test']\\ny_test = feature_sets['y_test']\\n\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "feature_sets_path = './'\n",
    "feature_sets_filename = 'all_targets_mfcc_sets.npz'\n",
    "# Load feature sets\n",
    "feature_sets = np.load(os.path.join(feature_sets_path, feature_sets_filename))\n",
    "print(feature_sets.files)\n",
    "# Assign feature sets\n",
    "x_train = feature_sets['x_train']\n",
    "y_train = feature_sets['y_train']\n",
    "x_val = feature_sets['x_val']\n",
    "y_val = feature_sets['y_val']\n",
    "x_test = feature_sets['x_test']\n",
    "y_test = feature_sets['y_test']\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. set parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17429, 16, 32, 1)\n",
      "(17429,)\n",
      "(2172, 16, 32, 1)\n",
      "(2172,)\n",
      "(2176, 16, 32, 1)\n",
      "(2176,)\n"
     ]
    }
   ],
   "source": [
    "train_list = list(zip(x_train, y_train))\n",
    "random.shuffle(train_list)\n",
    "x_train, y_train = zip(*train_list)\n",
    "\n",
    "val_list = list(zip(x_val, y_val))\n",
    "random.shuffle(val_list)\n",
    "x_val, y_val = zip(*val_list)\n",
    "\n",
    "test_list = list(zip(x_test, y_test))\n",
    "random.shuffle(test_list)\n",
    "x_test, y_test = zip(*test_list)\n",
    "\n",
    "x_tn = np.array(x_train)\n",
    "y_tn = np.array(y_train)\n",
    "x_v = np.array(x_val)\n",
    "y_v = np.array(y_val)\n",
    "x_ts = np.array(x_test)\n",
    "y_ts = np.array(y_test)\n",
    "\n",
    "x_tn = np.expand_dims(x_tn, axis=-1)\n",
    "x_v = np.expand_dims(x_v, axis=-1)\n",
    "x_ts = np.expand_dims(x_ts, axis=-1)\n",
    "\n",
    "print (x_tn.shape)\n",
    "print (y_tn.shape)\n",
    "print (x_v.shape)\n",
    "print (y_v.shape)\n",
    "print (x_ts.shape)\n",
    "print (y_ts.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (16, 32, 1)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 14, 30, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 12, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 26, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 5, 13, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 5, 13, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4160)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               532608    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 561,446\n",
      "Trainable params: 561,446\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "tmp = get_features(get_waveform(dataset_commands_filepaths[0]))\n",
    "tmp = np.expand_dims(tmp, axis=-1)\n",
    "input_shape = tmp.shape\n",
    "print('Input shape:', input_shape)\n",
    "num_labels = len(commands)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.Conv2D(32, 3, activation='relu'),\n",
    "    layers.Conv2D(32, 3, activation='relu'),\n",
    "    layers.Conv2D(64, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(num_labels),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "3486/3486 [==============================] - 16s 3ms/step - loss: 0.8927 - accuracy: 0.6895 - val_loss: 0.3141 - val_accuracy: 0.8789\n",
      "Epoch 2/500\n",
      "3486/3486 [==============================] - 9s 3ms/step - loss: 0.3220 - accuracy: 0.8838 - val_loss: 0.2883 - val_accuracy: 0.8936\n",
      "Epoch 3/500\n",
      "3486/3486 [==============================] - 9s 2ms/step - loss: 0.2527 - accuracy: 0.9108 - val_loss: 0.4315 - val_accuracy: 0.8642\n",
      "Epoch 4/500\n",
      "3486/3486 [==============================] - 9s 2ms/step - loss: 0.2399 - accuracy: 0.9169 - val_loss: 0.2796 - val_accuracy: 0.9010\n",
      "Epoch 5/500\n",
      "3486/3486 [==============================] - 9s 2ms/step - loss: 0.1944 - accuracy: 0.9332 - val_loss: 0.3093 - val_accuracy: 0.9111\n",
      "Epoch 6/500\n",
      "3486/3486 [==============================] - 9s 2ms/step - loss: 0.1727 - accuracy: 0.9427 - val_loss: 0.3184 - val_accuracy: 0.9098\n",
      "Epoch 7/500\n",
      "3486/3486 [==============================] - 9s 2ms/step - loss: 0.1555 - accuracy: 0.9472 - val_loss: 0.2985 - val_accuracy: 0.9015\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 500\n",
    "history = model.fit(\n",
    "    x_tn,y_tn,\n",
    "    validation_data=(x_v,y_v),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=5,\n",
    "    callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=10),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'SpeechCommandRecognition_model.h5'\n",
    "# Save the model as a file\n",
    "models.save_model(model, model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. inference on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import lite\n",
    "from tensorflow.keras import models\n",
    "# Parameters\n",
    "keras_model_filename = 'SpeechCommandRecognition_model.h5'\n",
    "tflite_filename = 'SpeechCommandRecognition_model.tflite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp22msj7qx/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp22msj7qx/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2248980"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert model to TF Lite model\n",
    "model = models.load_model(keras_model_filename)\n",
    "converter = lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "open(tflite_filename, 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of train_unknown_commands_features: 2480\n",
      "num of train_unknown_commands_label_id: 2480\n",
      "-\n",
      "num of val_unknown_commands_features: 310\n",
      "num of val_unknown_commands_label_id: 310\n",
      "-\n",
      "num of test_unknown_commands_features: 310\n",
      "num of test_unknown_commands_label_id: 310\n",
      "947\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print ('num of train_unknown_commands_features:', len(train_unknown_commands_features))\n",
    "print ('num of train_unknown_commands_label_id:', len(train_unknown_commands_label_id))\n",
    "print('-')\n",
    "print ('num of val_unknown_commands_features:', len(val_unknown_commands_features))\n",
    "print ('num of val_unknown_commands_label_id:', len(val_unknown_commands_label_id))\n",
    "print('-')\n",
    "print ('num of test_unknown_commands_features:', len(test_unknown_commands_features))\n",
    "print ('num of test_unknown_commands_label_id:', len(test_unknown_commands_label_id)) \n",
    "i=random.randrange(0, len(train_unknown_commands_features))\n",
    "print (i)\n",
    "print (train_unknown_commands_label_id[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of train_slience_commands_features: 2490\n",
      "num of train_slience_commands_label_id: 2490\n",
      "-\n",
      "num of val_slience_commands_features: 306\n",
      "num of val_slience_commands_label_id: 306\n",
      "-\n",
      "num of test_slience_commands_features: 306\n",
      "num of test_slience_commands_label_id: 306\n",
      "160\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print ('num of train_slience_commands_features:', len(train_slience_commands_features))\n",
    "print ('num of train_slience_commands_label_id:', len(train_slience_commands_label_id))\n",
    "print('-')\n",
    "print ('num of val_slience_commands_features:', len(val_slience_commands_features))\n",
    "print ('num of val_slience_commands_label_id:', len(val_slience_commands_label_id))\n",
    "print('-')\n",
    "print ('num of test_slience_commands_features:', len(test_slience_commands_features))\n",
    "print ('num of test_slience_commands_label_id:', len(test_slience_commands_label_id)) \n",
    "\n",
    "i=random.randrange(0, len(train_slience_commands_features))\n",
    "print (i)\n",
    "print (train_slience_commands_label_id[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
